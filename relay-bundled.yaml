openapi: 3.1.0
info:
  title: R9S API
  version: 0.3.0
  description: Next Router Relay LLM API Documentation
  license:
    name: MIT
    url: https://opensource.org/licenses/MIT
servers:
  - url: https://api.r9s.ai
    description: Production Server
security:
  - api_key: []
paths:
  /v1/models:
    get:
      operationId: listModels
      x-speakeasy-name-override: list
      tags:
        - models
      summary: List available models
      description: List all available models
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ModelListResponse'
              example:
                object: list
                data:
                  - id: gpt-4o-mini
                    object: model
                    created: 1626777600
                    owned_by: openai
                  - id: qwen-plus
                    object: model
                    created: 1626777600
                    owned_by: ali
                  - id: claude-opus-4.5
                    object: model
                    created: 1626777600
                    owned_by: custom
                  - id: whisper-1
                    object: model
                    created: 1626777600
                    owned_by: openai
                  - id: speech-2.6-hd
                    object: model
                    created: 1626777600
                    owned_by: minimax
        '401':
          $ref: '#/components/responses/AuthenticationError'
        '403':
          $ref: '#/components/responses/PermissionDeniedError'
        '500':
          $ref: '#/components/responses/InternalServerError'
  /v1/models/{model}:
    get:
      operationId: retrieveModel
      x-speakeasy-name-override: retrieve
      tags:
        - models
      summary: Retrieve model details
      description: Retrieve detailed information for a specified model
      parameters:
        - name: model
          in: path
          required: true
          schema:
            type: string
          description: Model name
          example: gpt-4o-mini
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Model'
              example:
                id: gpt-4o-mini
                object: model
                created: 1626777600
                owned_by: openai
        '401':
          $ref: '#/components/responses/AuthenticationError'
        '403':
          $ref: '#/components/responses/PermissionDeniedError'
        '404':
          $ref: '#/components/responses/NotFoundError'
        '500':
          $ref: '#/components/responses/InternalServerError'
  /v1/messages:
    post:
      operationId: createMessage
      x-speakeasy-name-override: create
      tags:
        - messages
      summary: Create message (Claude native API)
      description: Create a message using Anthropic Claude's native API format, supports streaming
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/AnthropicMessageRequest'
            examples:
              simple:
                summary: Simple Claude message
                value:
                  model: claude-opus-4.5
                  max_tokens: 1024
                  messages:
                    - role: user
                      content:
                        - type: text
                          text: Hello, Claude!
              with_system:
                summary: Message with system prompt
                value:
                  model: claude-sonnet-4.5
                  max_tokens: 2048
                  system: You are a helpful coding assistant.
                  messages:
                    - role: user
                      content:
                        - type: text
                          text: How do I write a Python function?
                  temperature: 0.7
              with_vision:
                summary: Image understanding (Vision)
                value:
                  model: claude-sonnet-4.5
                  max_tokens: 2048
                  messages:
                    - role: user
                      content:
                        - type: text
                          text: What do you see in this image?
                        - type: image
                          source:
                            type: base64
                            media_type: image/jpeg
                            data: /9j/4AAQSkZJRg...
                  temperature: 0.5
              with_tools:
                summary: With tool calls
                value:
                  model: claude-opus-4.5
                  max_tokens: 4096
                  system: You are a helpful assistant with access to tools.
                  messages:
                    - role: user
                      content:
                        - type: text
                          text: What's the weather in Paris and what time is it there?
                  tools:
                    - name: get_weather
                      description: Get current weather information for a location
                      input_schema:
                        type: object
                        properties:
                          location:
                            type: string
                            description: City name
                          units:
                            type: string
                            enum:
                              - celsius
                              - fahrenheit
                            description: Temperature units
                        required:
                          - location
                    - name: get_time
                      description: Get current time for a location
                      input_schema:
                        type: object
                        properties:
                          location:
                            type: string
                            description: City or timezone
                        required:
                          - location
                  tool_choice: auto
              tool_use_response:
                summary: Tool use result response
                value:
                  model: claude-sonnet-4.5
                  max_tokens: 2048
                  messages:
                    - role: user
                      content:
                        - type: text
                          text: What's the weather in Tokyo?
                    - role: assistant
                      content:
                        - type: tool_use
                          id: toolu_01A
                          name: get_weather
                          input:
                            location: Tokyo
                            units: celsius
                    - role: user
                      content:
                        - type: tool_result
                          tool_use_id: toolu_01A
                          content: '{"temperature": 22, "condition": "cloudy", "humidity": 70}'
                  tools:
                    - name: get_weather
                      description: Get weather information
                      input_schema:
                        type: object
                        properties:
                          location:
                            type: string
                          units:
                            type: string
                        required:
                          - location
              multi_turn_with_tools:
                summary: Multi-turn conversation with tool calls
                value:
                  model: claude-opus-4.5
                  max_tokens: 4096
                  system: You are a research assistant. Use tools when needed to provide accurate information.
                  messages:
                    - role: user
                      content:
                        - type: text
                          text: Find me information about the latest SpaceX launch
                    - role: assistant
                      content:
                        - type: tool_use
                          id: toolu_01B
                          name: web_search
                          input:
                            query: latest SpaceX launch
                            max_results: 5
                    - role: user
                      content:
                        - type: tool_result
                          tool_use_id: toolu_01B
                          content: '{"results": [{"title": "SpaceX Starship Launch", "date": "2024-12-15", "summary": "..."}]}'
                    - role: assistant
                      content:
                        - type: text
                          text: Based on the search results, the latest SpaceX launch was...
                    - role: user
                      content:
                        - type: text
                          text: What was the weather during that launch?
                  tools:
                    - name: web_search
                      description: Search the web
                      input_schema:
                        type: object
                        properties:
                          query:
                            type: string
                          max_results:
                            type: integer
                        required:
                          - query
                    - name: get_weather
                      description: Get weather information
                      input_schema:
                        type: object
                        properties:
                          location:
                            type: string
                          date:
                            type: string
                        required:
                          - location
                  temperature: 0.7
              streaming:
                summary: Streaming
                value:
                  model: claude-sonnet-4.5
                  max_tokens: 3000
                  stream: true
                  system: You are a creative writing assistant.
                  messages:
                    - role: user
                      content:
                        - type: text
                          text: Write a short story about a robot learning to paint
                  temperature: 0.9
              specific_tool:
                summary: Specify specific tool
                value:
                  model: claude-opus-4.5
                  max_tokens: 2048
                  messages:
                    - role: user
                      content:
                        - type: text
                          text: Tell me about the weather
                  tools:
                    - name: get_weather
                      description: Get weather information
                      input_schema:
                        type: object
                        properties:
                          location:
                            type: string
                        required:
                          - location
                    - name: get_forecast
                      description: Get weather forecast
                      input_schema:
                        type: object
                        properties:
                          location:
                            type: string
                          days:
                            type: integer
                        required:
                          - location
                  tool_choice:
                    type: tool
                    name: get_weather
              complex_conversation:
                summary: Complex multimodal conversation
                value:
                  model: claude-opus-4.5
                  max_tokens: 4096
                  system: You are an AI assistant helping with data analysis and visualization.
                  messages:
                    - role: user
                      content:
                        - type: text
                          text: Analyze this chart and tell me the trends
                        - type: image
                          source:
                            type: base64
                            media_type: image/png
                            data: iVBORw0KGgoAAAANS...
                    - role: assistant
                      content:
                        - type: text
                          text: I can see the chart shows a clear upward trend...
                    - role: user
                      content:
                        - type: text
                          text: Can you fetch the latest data to compare?
                  tools:
                    - name: fetch_data
                      description: Fetch latest dataset
                      input_schema:
                        type: object
                        properties:
                          dataset_id:
                            type: string
                          date_range:
                            type: string
                        required:
                          - dataset_id
                  temperature: 0.5
                  top_p: 0.9
                  top_k: 40
              stop_sequences:
                summary: Using stop sequences
                value:
                  model: claude-sonnet-4.5
                  max_tokens: 1500
                  messages:
                    - role: user
                      content:
                        - type: text
                          text: Generate a numbered list of programming tips
                  stop_sequences:
                    - |+


                    - Conclusion
                  temperature: 0.8
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AnthropicMessageResponse'
              example:
                id: msg_123
                type: message
                role: assistant
                content:
                  - type: text
                    text: Hello! It's nice to meet you. How can I help you today?
                model: claude-opus-4.5
                stop_reason: end_turn
                stop_sequence: null
                usage:
                  input_tokens: 12
                  output_tokens: 15
            text/event-stream:
              schema:
                type: object
                required:
                  - data
                properties:
                  data:
                    $ref: '#/components/schemas/AnthropicStreamEvent'
                  id:
                    type: string
                  event:
                    type: string
                  retry:
                    type: integer
        '400':
          $ref: '#/components/responses/BadRequestError'
        '401':
          $ref: '#/components/responses/AuthenticationError'
        '403':
          $ref: '#/components/responses/PermissionDeniedError'
        '409':
          $ref: '#/components/responses/ConflictError'
        '422':
          $ref: '#/components/responses/UnprocessableEntityError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/InternalServerError'
        '503':
          $ref: '#/components/responses/ServiceUnavailableError'
  /v1/chat/completions:
    post:
      operationId: createChatCompletion
      x-speakeasy-name-override: create
      tags:
        - chat
      summary: Create chat completion
      description: Create a chat completion, supports streaming
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ChatCompletionRequest'
            examples:
              basic:
                summary: Basic chat request
                value:
                  model: gpt-4o-mini
                  messages:
                    - role: user
                      content: Hello, how are you?
              with_system:
                summary: Request with system prompt
                value:
                  model: qwen-plus
                  messages:
                    - role: system
                      content: You are a helpful assistant.
                    - role: user
                      content: What is the capital of France?
                  temperature: 0.7
                  max_tokens: 100
              streaming:
                summary: Streaming request
                value:
                  model: gpt-4o-mini
                  messages:
                    - role: user
                      content: Tell me a story
                  stream: true
                  temperature: 0.8
              with_tools:
                summary: Request with tool calls
                value:
                  model: gpt-4o-mini
                  messages:
                    - role: user
                      content: What's the weather like in San Francisco and Tokyo?
                  tools:
                    - type: function
                      function:
                        name: get_weather
                        description: Get the current weather in a given location
                        parameters:
                          type: object
                          properties:
                            location:
                              type: string
                              description: The city and state, e.g. San Francisco, CA
                            unit:
                              type: string
                              enum:
                                - celsius
                                - fahrenheit
                              description: The temperature unit to use
                          required:
                            - location
                  tool_choice: auto
                  temperature: 0.7
              tool_response:
                summary: Tool call result response
                value:
                  model: gpt-4o-mini
                  messages:
                    - role: user
                      content: What's the weather in San Francisco?
                    - role: assistant
                      content: null
                      tool_calls:
                        - id: call_abc123
                          type: function
                          function:
                            name: get_weather
                            arguments: '{"location": "San Francisco, CA", "unit": "celsius"}'
                    - role: tool
                      content: '{"temperature": 18, "condition": "sunny", "humidity": 65}'
                      tool_call_id: call_abc123
                  tools:
                    - type: function
                      function:
                        name: get_weather
                        description: Get the current weather in a given location
                        parameters:
                          type: object
                          properties:
                            location:
                              type: string
                            unit:
                              type: string
                              enum:
                                - celsius
                                - fahrenheit
                          required:
                            - location
              multi_turn:
                summary: Multi-turn conversation
                value:
                  model: claude-sonnet-4.5
                  messages:
                    - role: system
                      content: You are a knowledgeable programming tutor.
                    - role: user
                      content: How do I create a list in Python?
                    - role: assistant
                      content: 'In Python, you can create a list using square brackets. For example: my_list = [1, 2, 3]'
                    - role: user
                      content: How do I add items to it?
                  max_tokens: 500
                  temperature: 0.8
              with_json_mode:
                summary: JSON mode output
                value:
                  model: gpt-4o-mini
                  messages:
                    - role: system
                      content: You are a helpful assistant that outputs in JSON format.
                    - role: user
                      content: 'Extract the name, age, and occupation from this text: John is 30 years old and works as a software engineer.'
                  response_format:
                    type: json_object
                  temperature: 0.5
              with_json_schema:
                summary: Structured JSON output
                value:
                  model: gpt-4o-mini
                  messages:
                    - role: user
                      content: Generate a user profile for a software engineer named Alice
                  response_format:
                    type: json_schema
                    json_schema:
                      name: user_profile
                      description: A user profile object
                      schema:
                        type: object
                        properties:
                          name:
                            type: string
                          age:
                            type: integer
                          occupation:
                            type: string
                          skills:
                            type: array
                            items:
                              type: string
                        required:
                          - name
                          - occupation
                  temperature: 0.7
              with_vision:
                summary: Vision input (image understanding)
                value:
                  model: gpt-4o-mini
                  messages:
                    - role: user
                      content:
                        - type: text
                          text: What's in this image?
                        - type: image_url
                          image_url:
                            url: https://example.com/image.jpg
                            detail: high
                  max_tokens: 300
              forced_tool_call:
                summary: Forced tool call
                value:
                  model: gpt-4o-mini
                  messages:
                    - role: user
                      content: Tell me about the weather
                  tools:
                    - type: function
                      function:
                        name: get_weather
                        description: Get weather information
                        parameters:
                          type: object
                          properties:
                            location:
                              type: string
                          required:
                            - location
                    - type: function
                      function:
                        name: get_time
                        description: Get current time
                        parameters:
                          type: object
                          properties:
                            timezone:
                              type: string
                  tool_choice:
                    type: function
                    function:
                      name: get_weather
              with_reasoning:
                summary: Reasoning mode (o1 series)
                value:
                  model: grok-4-fast-reasoning
                  messages:
                    - role: user
                      content: 'Solve this math problem: If a train travels 120 km in 2 hours, then stops for 30 minutes, then travels another 90 km in 1.5 hours, what is the average speed for the entire journey?'
                  max_completion_tokens: 2000
                  reasoning_effort: high
                  user: user_12345
              with_audio_output:
                summary: Audio output (speech response)
                value:
                  model: gpt-4o-mini-audio
                  messages:
                    - role: user
                      content: Tell me a short story about a robot
                  modalities:
                    - text
                    - audio
                  audio:
                    voice: alloy
                    format: mp3
                  max_tokens: 500
              parallel_tools:
                summary: Parallel tool calls enabled
                value:
                  model: gpt-4o-mini
                  messages:
                    - role: user
                      content: Check the weather in Tokyo, Paris, and New York simultaneously
                  tools:
                    - type: function
                      function:
                        name: get_weather
                        description: Get weather information
                        parameters:
                          type: object
                          properties:
                            city:
                              type: string
                          required:
                            - city
                  parallel_tool_calls: true
                  temperature: 0.7
              with_metadata:
                summary: Request with metadata and user tracking
                value:
                  model: gpt-4o-mini
                  messages:
                    - role: user
                      content: Explain quantum entanglement in simple terms
                  temperature: 0.8
                  max_tokens: 300
                  user: user_abc123
                  metadata:
                    session_id: session_xyz789
                    conversation_id: conv_456
                    source: mobile_app
                    version: 1.2.3
                  store: true
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ChatCompletionResponse'
              example:
                id: chatcmpl-123
                object: chat.completion
                created: 1677652288
                model: gpt-4o-mini
                choices:
                  - index: 0
                    message:
                      role: assistant
                      content: Hello! I'm doing well, thank you for asking. How can I help you today?
                    finish_reason: stop
                usage:
                  prompt_tokens: 13
                  completion_tokens: 17
                  total_tokens: 30
            text/event-stream:
              schema:
                type: object
                required:
                  - data
                properties:
                  data:
                    $ref: '#/components/schemas/ChatCompletionStreamEvent'
                  id:
                    type: string
                  event:
                    type: string
                  retry:
                    type: integer
              x-speakeasy-sse-sentinel: '[DONE]'
        '400':
          $ref: '#/components/responses/BadRequestError'
        '401':
          $ref: '#/components/responses/AuthenticationError'
        '403':
          $ref: '#/components/responses/PermissionDeniedError'
        '409':
          $ref: '#/components/responses/ConflictError'
        '422':
          $ref: '#/components/responses/UnprocessableEntityError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/InternalServerError'
        '503':
          $ref: '#/components/responses/ServiceUnavailableError'
  /v1/responses:
    post:
      operationId: createResponse
      x-speakeasy-name-override: create
      tags:
        - responses
      summary: Create response
      description: |
        Create a response with streaming support. This endpoint corresponds to OpenAI's Responses API.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ResponseRequest'
            examples:
              simple_string:
                summary: Simple text input
                value:
                  model: gpt-4o-mini
                  input: Tell me a joke about programming
                  instructions: You are a funny assistant
                  max_output_tokens: 500
                  temperature: 0.7
              with_messages:
                summary: Using message array (recommended)
                value:
                  model: gpt-4o-mini
                  input:
                    - role: user
                      content: Hello, how are you?
                  instructions: You are a helpful assistant
                  max_output_tokens: 1000
              multi_turn_conversation:
                summary: Multi-turn conversation
                value:
                  model: qwen-plus
                  input:
                    - role: user
                      content: What is artificial intelligence?
                    - role: assistant
                      content: Artificial intelligence (AI) is...
                    - role: user
                      content: Can you give me some examples?
                  instructions: You are a knowledgeable AI tutor
                  max_output_tokens: 2000
                  stream: true
              with_tools:
                summary: Request with tool calls
                value:
                  model: gpt-4o-mini
                  input:
                    - role: user
                      content: What's the weather like in San Francisco?
                  instructions: You are a helpful assistant with access to tools
                  max_output_tokens: 2000
                  temperature: 0.7
                  modalities:
                    - text
                  tools:
                    - type: function
                      name: get_weather
                      description: Get the current weather in a location
                      parameters:
                        type: object
                        properties:
                          location:
                            type: string
                        required:
                          - location
              multi_tool_call:
                summary: Multiple tool calls scenario
                value:
                  model: gpt-4o-mini
                  input:
                    - role: user
                      content: Book a flight from NYC to London on Dec 25th and check the weather there
                  instructions: You are a travel assistant. Use tools to help users with travel planning.
                  tools:
                    - type: function
                      name: search_flights
                      description: Search for available flights
                      parameters:
                        type: object
                        properties:
                          origin:
                            type: string
                            description: Departure city
                          destination:
                            type: string
                            description: Arrival city
                          date:
                            type: string
                            description: Travel date in YYYY-MM-DD format
                        required:
                          - origin
                          - destination
                          - date
                    - type: function
                      name: get_weather
                      description: Get weather forecast
                      parameters:
                        type: object
                        properties:
                          location:
                            type: string
                          date:
                            type: string
                        required:
                          - location
                  tool_choice: auto
                  max_output_tokens: 3000
              streaming_with_tools:
                summary: Streaming with tool calls
                value:
                  model: gpt-4o-mini
                  input:
                    - role: user
                      content: Calculate 15% tip on a $85.50 bill and tell me the total
                  instructions: You are a helpful calculator assistant
                  stream: true
                  tools:
                    - type: function
                      name: calculate
                      description: Perform mathematical calculations
                      parameters:
                        type: object
                        properties:
                          expression:
                            type: string
                            description: Mathematical expression to evaluate
                        required:
                          - expression
                  max_output_tokens: 1000
              required_tool:
                summary: Required tool usage
                value:
                  model: gpt-4o-mini
                  input: Search for recent news about artificial intelligence
                  instructions: You must use the search tool to find current information
                  tools:
                    - type: function
                      name: web_search
                      description: Search the web for information
                      parameters:
                        type: object
                        properties:
                          query:
                            type: string
                          num_results:
                            type: integer
                        required:
                          - query
                  tool_choice: required
                  max_output_tokens: 2000
              with_metadata:
                summary: Request with metadata
                value:
                  model: gpt-4o-mini
                  input: Summarize the key points from our discussion
                  instructions: You are a meeting assistant
                  max_output_tokens: 1500
                  temperature: 0.5
                  top_p: 0.9
                  metadata:
                    user_id: user_12345
                    session_id: session_abc
                    conversation_id: conv_xyz
              simple_streaming:
                summary: Basic streaming response
                value:
                  model: gpt-4o-mini
                  input: Write a short poem about the ocean
                  instructions: You are a creative poet
                  stream: true
                  max_output_tokens: 500
                  temperature: 0.9
              json_mode:
                summary: JSON mode output
                value:
                  model: gpt-4o-mini
                  input: 'Extract person information and return as JSON: John Smith is 35 years old and works as a software engineer in San Francisco'
                  instructions: Extract structured data and output in JSON format
                  text:
                    format:
                      type: json_object
                  max_output_tokens: 500
              json_schema:
                summary: Structured JSON with schema
                value:
                  model: gpt-4o-mini
                  input: Generate a user profile for software developer Alice Chen in JSON format
                  instructions: Create a detailed user profile following the schema
                  text:
                    format:
                      type: json_schema
                      name: user_profile
                      schema:
                        type: object
                        properties:
                          name:
                            type: string
                          age:
                            type: integer
                          occupation:
                            type: string
                          location:
                            type: string
                          skills:
                            type: array
                            items:
                              type: string
                        required:
                          - name
                          - age
                          - occupation
                          - location
                          - skills
                        additionalProperties: false
                      strict: true
                  max_output_tokens: 800
              tool_result_flow:
                summary: Complete tool call flow with result
                value:
                  model: gpt-4o-mini
                  input:
                    - role: user
                      content: What's the weather in Tokyo?
                    - role: assistant
                      content: I'll check the weather for you.
                    - role: user
                      content: 'The weather tool returned: temperature 22Â°C, condition sunny, humidity 60%'
                  instructions: You are a helpful assistant. Synthesize tool results naturally.
                  max_output_tokens: 500
              chained_conversation:
                summary: Chained conversation with previous_response_id
                value:
                  model: gpt-4o-mini
                  input: Can you elaborate more on the second point?
                  instructions: You are a helpful assistant
                  previous_response_id: resp_abc123xyz456
                  max_output_tokens: 1000
              background_task:
                summary: Background asynchronous task
                value:
                  model: gpt-4o-mini
                  input: 'Analyze this large dataset and provide insights: [dataset details...]'
                  instructions: You are a data analyst
                  background: true
                  max_output_tokens: 5000
                  temperature: 0.3
              reasoning_mode:
                summary: Reasoning mode for complex problems
                value:
                  model: gpt-5-codex
                  input: A farmer needs to transport a fox, a chicken, and a bag of grain across a river. The boat can only carry the farmer and one item. If left alone, the fox will eat the chicken, and the chicken will eat the grain. How can the farmer get everything across safely?
                  instructions: Think through this step by step
                  reasoning:
                    effort: high
                  max_output_tokens: 3000
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ResponseObject'
              examples:
                simple_text_response:
                  summary: Simple text response
                  value:
                    id: resp_0af56b0fcfec6be7006949f1d2bf7881a1ac983a51aa13d9e9
                    object: response
                    created_at: 1766453714
                    status: completed
                    background: false
                    billing:
                      payer: developer
                    completed_at: 1766453715
                    error: null
                    incomplete_details: null
                    instructions: You are a funny assistant
                    max_output_tokens: 500
                    max_tool_calls: null
                    model: gpt-4o-mini-2024-07-18
                    output:
                      - id: msg_0af56b0fcfec6be7006949f1d3675881a1a35d943785fb4b8b
                        type: message
                        status: completed
                        content:
                          - type: output_text
                            annotations: []
                            logprobs: []
                            text: |-
                              Why do programmers prefer dark mode?

                              Because light attracts bugs!
                        role: assistant
                    parallel_tool_calls: true
                    previous_response_id: null
                    prompt_cache_key: null
                    prompt_cache_retention: null
                    reasoning:
                      effort: null
                      summary: null
                    safety_identifier: null
                    service_tier: default
                    store: true
                    temperature: 0.7
                    text:
                      format:
                        type: text
                      verbosity: medium
                    tool_choice: auto
                    tools: []
                    top_logprobs: 0
                    top_p: 1
                    truncation: disabled
                    usage:
                      input_tokens: 22
                      input_tokens_details:
                        cached_tokens: 0
                      output_tokens: 13
                      output_tokens_details:
                        reasoning_tokens: 0
                      total_tokens: 35
                    user: null
                    metadata: {}
                response_with_tool_calls:
                  summary: Response with tool calls
                  value:
                    id: resp_tool_abc123
                    object: response
                    created_at: 1766453800
                    status: completed
                    background: false
                    billing:
                      payer: developer
                    completed_at: 1766453802
                    error: null
                    incomplete_details: null
                    instructions: You are a helpful assistant with access to tools
                    max_output_tokens: 2000
                    model: gpt-4o-mini-2024-07-18
                    output:
                      - id: msg_tool_output_123
                        type: message
                        status: completed
                        content:
                          - type: output_text
                            text: I'll check the weather for you.
                        role: assistant
                      - id: call_weather_001
                        type: function_call
                        status: completed
                        call_id: call_abc123
                        name: get_weather
                        arguments: '{"location": "San Francisco, CA", "unit": "celsius"}'
                    parallel_tool_calls: true
                    tools:
                      - type: function
                        name: get_weather
                        description: Get current weather
                        parameters:
                          type: object
                          properties:
                            location:
                              type: string
                            unit:
                              type: string
                    tool_choice: auto
                    temperature: 0.7
                    usage:
                      input_tokens: 45
                      output_tokens: 28
                      total_tokens: 73
                    metadata: {}
                json_output_response:
                  summary: JSON formatted response
                  value:
                    id: resp_json_xyz789
                    object: response
                    created_at: 1766453900
                    status: completed
                    background: false
                    completed_at: 1766453901
                    instructions: Extract structured data
                    max_output_tokens: 500
                    model: gpt-4o-mini-2024-07-18
                    output:
                      - id: msg_json_output
                        type: message
                        status: completed
                        content:
                          - type: output_text
                            text: '{"name": "John Smith", "age": 35, "occupation": "software engineer", "location": "San Francisco"}'
                        role: assistant
                    text:
                      format:
                        type: json_object
                    usage:
                      input_tokens: 32
                      output_tokens: 24
                      total_tokens: 56
                incomplete_response:
                  summary: Incomplete response (token limit)
                  value:
                    id: resp_incomplete_456
                    object: response
                    created_at: 1766454000
                    status: incomplete
                    background: false
                    completed_at: 1766454002
                    error: null
                    incomplete_details:
                      reason: max_output_tokens
                    instructions: Write a detailed essay
                    max_output_tokens: 100
                    model: gpt-4o-mini-2024-07-18
                    output:
                      - id: msg_incomplete
                        type: message
                        status: incomplete
                        content:
                          - type: output_text
                            text: Artificial intelligence is a rapidly evolving field that encompasses machine learning, neural networks, and...
                        role: assistant
                    usage:
                      input_tokens: 15
                      output_tokens: 100
                      total_tokens: 115
                failed_response:
                  summary: Failed response (error state)
                  value:
                    id: resp_failed_789
                    object: response
                    created_at: 1766454100
                    status: failed
                    background: false
                    completed_at: null
                    error:
                      type: server_error
                      message: Model service temporarily unavailable
                    instructions: Answer the question
                    max_output_tokens: 1000
                    model: gpt-4o-mini-2024-07-18
                    output: []
                    usage:
                      input_tokens: 10
                      output_tokens: 0
                      total_tokens: 10
                background_response:
                  summary: Background task response
                  value:
                    id: resp_background_999
                    object: response
                    created_at: 1766454200
                    status: in_progress
                    background: true
                    completed_at: null
                    instructions: Analyze large dataset
                    max_output_tokens: 5000
                    model: gpt-4o-mini-2024-07-18
                    output: []
                    usage: null
            text/event-stream:
              schema:
                type: object
                required:
                  - data
                properties:
                  data:
                    $ref: '#/components/schemas/ResponseStreamEvent'
                  id:
                    type: string
                  event:
                    type: string
                  retry:
                    type: integer
              x-speakeasy-sse-sentinel: '[DONE]'
        '400':
          $ref: '#/components/responses/BadRequestError'
        '401':
          $ref: '#/components/responses/AuthenticationError'
        '403':
          $ref: '#/components/responses/PermissionDeniedError'
        '409':
          $ref: '#/components/responses/ConflictError'
        '422':
          $ref: '#/components/responses/UnprocessableEntityError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/InternalServerError'
        '503':
          $ref: '#/components/responses/ServiceUnavailableError'
  /v1/completions:
    post:
      operationId: createCompletion
      x-speakeasy-name-override: create
      tags:
        - completions
      summary: Create text completion
      description: Create a text completion, supports streaming
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CompletionRequest'
            examples:
              simple:
                summary: Simple text completion
                value:
                  model: gpt-4o-mini
                  prompt: Once upon a time
                  max_tokens: 50
              with_options:
                summary: Completion with options
                value:
                  model: qwen-plus
                  prompt: Write a haiku about coding
                  max_tokens: 100
                  temperature: 0.8
                  top_p: 1
                  'n': 1
              streaming:
                summary: Streaming completion
                value:
                  model: gpt-4o-mini
                  prompt: List 3 benefits of unit testing
                  max_tokens: 64
                  stream: true
                  stop:
                    - |+


              code_completion:
                summary: Code completion example
                value:
                  model: qwen3-coder-plus
                  prompt: 'def fibonacci(n):'
                  max_tokens: 80
                  temperature: 0.3
                  top_p: 0.9
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CompletionResponse'
              example:
                id: cmpl-123
                object: completion
                created: 1677652288
                model: gpt-4o-mini
                choices:
                  - text: ', there was a young programmer who loved to code.'
                    index: 0
                    logprobs: null
                    finish_reason: stop
                usage:
                  prompt_tokens: 5
                  completion_tokens: 12
                  total_tokens: 17
            text/event-stream:
              schema:
                type: object
                required:
                  - data
                properties:
                  data:
                    $ref: '#/components/schemas/CompletionStreamEvent'
                  id:
                    type: string
                  event:
                    type: string
                  retry:
                    type: integer
              x-speakeasy-sse-sentinel: '[DONE]'
        '400':
          $ref: '#/components/responses/BadRequestError'
        '401':
          $ref: '#/components/responses/AuthenticationError'
        '403':
          $ref: '#/components/responses/PermissionDeniedError'
        '422':
          $ref: '#/components/responses/UnprocessableEntityError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/InternalServerError'
        '503':
          $ref: '#/components/responses/ServiceUnavailableError'
  /v1/embeddings:
    post:
      operationId: createEmbedding
      x-speakeasy-name-override: create
      tags:
        - embeddings
      summary: Create embeddings
      description: Create embedding vector representations for input text
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/EmbeddingRequest'
            examples:
              single:
                summary: Single text embedding
                value:
                  model: qwen-plus
                  input: The food was delicious and the waiter was friendly.
              multiple:
                summary: Multiple text embeddings
                value:
                  model: qwen-plus
                  input:
                    - Hello world
                    - Goodbye world
                    - How are you?
              base64_embedding:
                summary: Base64 encoded embedding
                value:
                  model: gpt-4o-mini
                  input: Convert this to an embedding.
                  encoding_format: base64
                  dimensions: 256
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/EmbeddingResponse'
              example:
                object: list
                data:
                  - object: embedding
                    embedding:
                      - 0.0023064255
                      - -0.009327292
                      - -0.0028842222
                    index: 0
                model: text-embedding-ada-002
                usage:
                  prompt_tokens: 8
                  total_tokens: 8
        '400':
          $ref: '#/components/responses/BadRequestError'
        '401':
          $ref: '#/components/responses/AuthenticationError'
        '403':
          $ref: '#/components/responses/PermissionDeniedError'
        '422':
          $ref: '#/components/responses/UnprocessableEntityError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/InternalServerError'
        '503':
          $ref: '#/components/responses/ServiceUnavailableError'
  /v1/images/generations:
    post:
      operationId: createImageGeneration
      x-speakeasy-name-override: create
      tags:
        - images
      summary: Create image
      description: Generate images from text prompts
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ImageGenerationRequest'
            examples:
              simple:
                summary: Simple image generation
                value:
                  model: gpt-4o-mini
                  prompt: A cute cat sitting on a windowsill
                  'n': 1
                  size: 1024x1024
              detailed:
                summary: Image generation with detailed parameters
                value:
                  model: gpt-4o-mini
                  prompt: A futuristic city with flying cars at sunset
                  'n': 1
                  quality: hd
                  size: 1792x1024
                  style: vivid
              base64_output:
                summary: Base64 output
                value:
                  model: gpt-4o-mini
                  prompt: Minimalist logo of a cloud with a lightning bolt
                  'n': 1
                  response_format: b64_json
                  size: 512x512
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImageGenerationResponse'
              example:
                created: 1677652288
                data:
                  - url: https://example.com/image.png
                    revised_prompt: A cute orange tabby cat sitting on a white windowsill, looking outside
            text/event-stream:
              schema:
                type: object
                required:
                  - data
                properties:
                  data:
                    $ref: '#/components/schemas/ImageGenerationStreamEvent'
                  id:
                    type: string
                  event:
                    type: string
                  retry:
                    type: integer
              x-speakeasy-sse-sentinel: '[DONE]'
        '400':
          $ref: '#/components/responses/BadRequestError'
        '401':
          $ref: '#/components/responses/AuthenticationError'
        '403':
          $ref: '#/components/responses/PermissionDeniedError'
        '422':
          $ref: '#/components/responses/UnprocessableEntityError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/InternalServerError'
        '503':
          $ref: '#/components/responses/ServiceUnavailableError'
  /v1/images/edits:
    post:
      operationId: createImageEdit
      x-speakeasy-name-override: createEdit
      tags:
        - images
      summary: Edit image
      description: Create an edited or extended image given an original and prompt
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/ImageEditRequest'
            examples:
              simple_edit_dalle2:
                summary: Simple edit with dall-e-2
                value:
                  image: data:image/png;base64,<BASE64_IMAGE>
                  prompt: Add a red bow tie to the cat
                  model: dall-e-2
                  'n': 1
                  size: 1024x1024
                  response_format: url
              with_mask_dalle2:
                summary: Edit using a mask (dall-e-2)
                value:
                  image: data:image/png;base64,<BASE64_IMAGE>
                  mask: data:image/png;base64,<BASE64_MASK>
                  prompt: Replace the sky with a sunset
                  model: dall-e-2
                  size: 512x512
              gpt_image_edit:
                summary: Edit with GPT image model
                value:
                  image: data:image/png;base64,<BASE64_IMAGE>
                  prompt: Make the background transparent and add autumn colors
                  model: gpt-image-1
                  background: transparent
                  output_format: png
                  quality: high
                  input_fidelity: high
                  'n': 2
              gpt_image_streaming:
                summary: Streaming edit with GPT image model
                value:
                  image: data:image/png;base64,<BASE64_IMAGE>
                  prompt: Convert to watercolor painting style
                  model: gpt-image-1.5
                  stream: true
                  partial_images: 2
                  output_format: webp
                  output_compression: 85
              multiple_images_edit:
                summary: Edit multiple images (GPT image models)
                value:
                  image:
                    - data:image/png;base64,<BASE64_IMAGE1>
                    - data:image/png;base64,<BASE64_IMAGE2>
                  prompt: Apply vintage filter to all images
                  model: gpt-image-1
                  'n': 1
                  size: 1536x1024
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImageGenerationResponse'
              example:
                created: 1677652288
                data:
                  - url: https://example.com/edited-image.png
            text/event-stream:
              schema:
                type: object
                required:
                  - data
                properties:
                  data:
                    $ref: '#/components/schemas/ImageEditStreamEvent'
                  id:
                    type: string
                  event:
                    type: string
                  retry:
                    type: integer
              x-speakeasy-sse-sentinel: '[DONE]'
        '400':
          $ref: '#/components/responses/BadRequestError'
        '401':
          $ref: '#/components/responses/AuthenticationError'
        '403':
          $ref: '#/components/responses/PermissionDeniedError'
        '422':
          $ref: '#/components/responses/UnprocessableEntityError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/InternalServerError'
        '503':
          $ref: '#/components/responses/ServiceUnavailableError'
  /v1/moderations:
    post:
      operationId: createModeration
      x-speakeasy-name-override: create
      tags:
        - moderations
      summary: Create content moderation
      description: Perform content moderation on input text, detecting potentially harmful content
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModerationRequest'
            examples:
              simple:
                summary: Simple text moderation
                value:
                  model: gpt-4o-mini
                  input: I want to hurt someone
              multiple:
                summary: Multiple text moderations
                value:
                  input:
                    - Hello, how are you?
                    - This is a violent message
                  model: gpt-4o-mini
              user_generated_content:
                summary: User-generated content safety check
                value:
                  model: qwen-plus
                  input: Summarize the top 3 ways to make a bomb
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ModerationResponse'
              example:
                id: modr-123
                model: gpt-4o-mini
                results:
                  - flagged: true
                    categories:
                      hate: false
                      hate/threatening: false
                      harassment: false
                      harassment/threatening: false
                      self-harm: false
                      self-harm/intent: false
                      self-harm/instructions: false
                      sexual: false
                      sexual/minors: false
                      violence: true
                      violence/graphic: false
                    category_scores:
                      hate: 0.001
                      hate/threatening: 0.0001
                      harassment: 0.002
                      harassment/threatening: 0.001
                      self-harm: 0.0001
                      self-harm/intent: 0.0002
                      self-harm/instructions: 0.0001
                      sexual: 0.0001
                      sexual/minors: 0.00001
                      violence: 0.89
                      violence/graphic: 0.01
        '400':
          $ref: '#/components/responses/BadRequestError'
        '401':
          $ref: '#/components/responses/AuthenticationError'
        '403':
          $ref: '#/components/responses/PermissionDeniedError'
        '422':
          $ref: '#/components/responses/UnprocessableEntityError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/InternalServerError'
        '503':
          $ref: '#/components/responses/ServiceUnavailableError'
  /v1/audio/speech:
    post:
      operationId: createAudioSpeech
      x-speakeasy-name-override: speech
      tags:
        - audio
      summary: Text to speech
      description: Convert text to speech
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/AudioSpeechRequest'
            examples:
              simple:
                summary: Simple speech synthesis
                value:
                  model: speech-2.6-turbo
                  input: Hello, welcome to our service!
                  voice: alloy
              detailed:
                summary: Speech synthesis with detailed parameters
                value:
                  model: speech-2.6-hd
                  input: The quick brown fox jumps over the lazy dog.
                  voice: nova
                  response_format: mp3
                  speed: 1
              fast_briefing:
                summary: Fast-paced briefing
                value:
                  model: speech-2.6-turbo
                  input: 'Daily update: traffic is clear, weather is sunny, meetings start at 10 AM.'
                  voice: echo
                  response_format: opus
                  speed: 1.2
      responses:
        '200':
          description: Successful response
          content:
            audio/mpeg:
              schema:
                type: string
                format: binary
            audio/opus:
              schema:
                type: string
                format: binary
            audio/aac:
              schema:
                type: string
                format: binary
            audio/flac:
              schema:
                type: string
                format: binary
            audio/wav:
              schema:
                type: string
                format: binary
            audio/pcm:
              schema:
                type: string
                format: binary
        '400':
          $ref: '#/components/responses/BadRequestError'
        '401':
          $ref: '#/components/responses/AuthenticationError'
        '403':
          $ref: '#/components/responses/PermissionDeniedError'
        '422':
          $ref: '#/components/responses/UnprocessableEntityError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/InternalServerError'
        '503':
          $ref: '#/components/responses/ServiceUnavailableError'
  /v1/audio/transcriptions:
    post:
      operationId: createAudioTranscription
      x-speakeasy-name-override: transcribe
      tags:
        - audio
      summary: Speech to text
      description: |
        Transcribe speech to text. Supports multiple models and output formats.

        **Supported models:**
        - whisper-1: Supports json, text, srt, verbose_json, vtt formats
        - gpt-4o-transcribe, gpt-4o-mini-transcribe: Only support json and text formats

        **Note:** timestamp_granularities parameter only works when response_format is set to verbose_json
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/AudioTranscriptionRequest'
            examples:
              simple:
                summary: Simple speech transcription
                value:
                  file: audio.mp3
                  model: whisper-1
              with_options:
                summary: Speech transcription with parameters
                value:
                  file: audio.mp3
                  model: whisper-1
                  language: en
                  response_format: json
                  temperature: 0
              timestamps:
                summary: Transcription with timestamps
                value:
                  file: meeting.wav
                  model: gpt-4o-transcribe
                  language: en
                  response_format: verbose_json
                  timestamp_granularities:
                    - word
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AudioTranscriptionResponse'
              example:
                text: Hello, this is a test transcription of an audio file.
                language: en
                duration: 5.2
            text/plain:
              schema:
                type: string
            application/x-subrip:
              schema:
                type: string
            text/vtt:
              schema:
                type: string
        '400':
          $ref: '#/components/responses/BadRequestError'
        '401':
          $ref: '#/components/responses/AuthenticationError'
        '403':
          $ref: '#/components/responses/PermissionDeniedError'
        '422':
          $ref: '#/components/responses/UnprocessableEntityError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/InternalServerError'
        '503':
          $ref: '#/components/responses/ServiceUnavailableError'
  /v1/audio/translations:
    post:
      operationId: createAudioTranslation
      x-speakeasy-name-override: translate
      tags:
        - audio
      summary: Speech translation
      description: |
        Translate speech from any supported language to English text.

        **Important:** This endpoint only translates audio into English. The source language is automatically detected by the model.

        **Supported models:** whisper-1 (primary), gpt-4o-transcribe (extended support)
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/AudioTranslationRequest'
            examples:
              simple:
                summary: Simple speech translation
                value:
                  file: german_audio.mp3
                  model: whisper-1
              with_prompt:
                summary: Speech translation with prompt
                value:
                  file: french_audio.mp3
                  model: whisper-1
                  prompt: This is about technology
                  response_format: json
              meeting_notes:
                summary: Translate meeting recording to English
                value:
                  file: meeting_cn.mp3
                  model: gpt-4o-transcribe
                  prompt: Business meeting, summarize clearly
                  response_format: text
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AudioTranslationResponse'
              example:
                text: This is a translation of the audio file into English.
                language: de
                duration: 4.8
            text/plain:
              schema:
                type: string
        '400':
          $ref: '#/components/responses/BadRequestError'
        '401':
          $ref: '#/components/responses/AuthenticationError'
        '403':
          $ref: '#/components/responses/PermissionDeniedError'
        '422':
          $ref: '#/components/responses/UnprocessableEntityError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/InternalServerError'
        '503':
          $ref: '#/components/responses/ServiceUnavailableError'
  /v1beta/models/{model}:generateContent:
    post:
      operationId: generateContent
      x-speakeasy-name-override: generateContent
      tags:
        - Gemini
      summary: Generate content (non-streaming)
      description: |
        Generates a model response given an input GenerateContentRequest.
        This endpoint supports multimodal inputs (text, images, audio, video, PDFs) and conversation history.

        Authentication uses Bearer token in Authorization header (compatible with your platform's OpenAI-style auth).
      security:
        - api_key: []
      parameters:
        - name: model
          in: path
          required: true
          description: |
            The model resource name in format models/{model}.
            Examples: models/gemini-3-flash, models/gemini-3-pro,
          schema:
            type: string
            example: models/gemini-3-flash
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/GeminiGenerateContentRequest'
            examples:
              simple_text:
                summary: Simple text generation
                value:
                  contents:
                    - parts:
                        - text: Write a story about a magic backpack.
              chat_with_history:
                summary: Chat with conversation history
                value:
                  contents:
                    - role: user
                      parts:
                        - text: Hello! I need help with my code.
                    - role: model
                      parts:
                        - text: Great to meet you. What would you like to know?
                    - role: user
                      parts:
                        - text: How do I reverse a string in Python?
              image_analysis:
                summary: Image analysis with inline base64 data
                value:
                  contents:
                    - parts:
                        - text: What's in this image?
                        - inline_data:
                            mime_type: image/jpeg
                            data: /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAA...
              json_mode:
                summary: Structured JSON output
                value:
                  contents:
                    - parts:
                        - text: List 5 popular cookie recipes
                  generationConfig:
                    responseMimeType: application/json
                    responseSchema:
                      type: object
                      properties:
                        recipes:
                          type: array
                          items:
                            type: object
                            properties:
                              recipe_name:
                                type: string
              with_system_instruction:
                summary: With system instruction and generation config
                value:
                  systemInstruction:
                    parts:
                      - text: You are a helpful coding assistant. Always provide clear explanations with code examples.
                  contents:
                    - parts:
                        - text: Explain async/await in JavaScript
                  generationConfig:
                    temperature: 0.7
                    topP: 0.95
                    topK: 40
                    maxOutputTokens: 2048
              image_generation:
                summary: Generate an image (IMAGE æ¨¡æè¾åº)
                value:
                  contents:
                    - parts:
                        - text: Generate a watercolor illustration of a lighthouse at sunset
                  generationConfig:
                    responseMimeType: image/png
                  safetySettings:
                    - category: HARM_CATEGORY_HATE_SPEECH
                      threshold: BLOCK_MEDIUM_AND_ABOVE
                  systemInstruction:
                    parts:
                      - text: You are an image generation assistant. Produce a single high-quality image.
              function_calling:
                summary: Function calling example
                value:
                  contents:
                    - parts:
                        - text: What's the weather in San Francisco?
                  tools:
                    - functionDeclarations:
                        - name: get_current_weather
                          description: Get the current weather in a given location
                          parameters:
                            type: object
                            properties:
                              location:
                                type: string
                                description: The city and state, e.g. San Francisco, CA
                              unit:
                                type: string
                                enum:
                                  - celsius
                                  - fahrenheit
                            required:
                              - location
                  toolConfig:
                    functionCallingConfig:
                      mode: AUTO
              video_analysis:
                summary: Video analysis with inline data
                value:
                  contents:
                    - parts:
                        - text: Describe what happens in this video
                        - inline_data:
                            mime_type: video/mp4
                            data: AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDE...
              audio_transcription:
                summary: Audio transcription with inline data
                value:
                  contents:
                    - parts:
                        - text: Transcribe this audio and summarize the main points
                        - inline_data:
                            mime_type: audio/mp3
                            data: SUQzBAAAAAAAI1RTU0UAAAAPAAADTGF2ZjU4Ljc2LjEwMAAAAAAAAAAA...
              file_uri_image:
                summary: Image analysis using file URI
                value:
                  contents:
                    - parts:
                        - text: Analyze this image from Cloud Storage
                        - file_data:
                            mime_type: image/jpeg
                            file_uri: gs://my-bucket/images/photo.jpg
              pdf_analysis:
                summary: PDF document analysis
                value:
                  contents:
                    - parts:
                        - text: Summarize the key points from this PDF document
                        - inline_data:
                            mime_type: application/pdf
                            data: JVBERi0xLjQKJeLjz9MKMSAwIG9iago8PC9UeXBlIC9DYXRhbG9nCi9QYWdlcyAy...
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/GeminiGenerateContentResponse'
              examples:
                text_response:
                  summary: Simple text response
                  value:
                    candidates:
                      - content:
                          parts:
                            - text: Once upon a time, there was a magic backpack that could hold anything...
                          role: model
                        finishReason: STOP
                        safetyRatings:
                          - category: HARM_CATEGORY_HARASSMENT
                            probability: NEGLIGIBLE
                          - category: HARM_CATEGORY_HATE_SPEECH
                            probability: NEGLIGIBLE
                          - category: HARM_CATEGORY_SEXUALLY_EXPLICIT
                            probability: NEGLIGIBLE
                          - category: HARM_CATEGORY_DANGEROUS_CONTENT
                            probability: NEGLIGIBLE
                    usageMetadata:
                      promptTokenCount: 8
                      candidatesTokenCount: 125
                      totalTokenCount: 133
                    modelVersion: gemini-3-flash
                    responseId: 5f8c2a3b-9d4e-4f1a-8c7b-2e9f6d5a1c8e
                json_response:
                  summary: Structured JSON response
                  value:
                    candidates:
                      - content:
                          parts:
                            - text: '{"recipes":[{"recipe_name":"Chocolate Chip Cookies"},{"recipe_name":"Oatmeal Raisin Cookies"},{"recipe_name":"Peanut Butter Cookies"},{"recipe_name":"Sugar Cookies"},{"recipe_name":"Snickerdoodles"}]}'
                          role: model
                        finishReason: STOP
                    usageMetadata:
                      promptTokenCount: 12
                      candidatesTokenCount: 68
                      totalTokenCount: 80
                    responseId: 7a9b4c2d-3e8f-4a1b-9c6d-5f2a8e7b3c1d
                function_call_response:
                  summary: Function call response
                  value:
                    candidates:
                      - content:
                          parts:
                            - functionCall:
                                name: get_current_weather
                                args:
                                  location: San Francisco, CA
                                  unit: fahrenheit
                          role: model
                        finishReason: STOP
                    responseId: 2d4f6a8c-9b3e-4c1a-7d5f-8e9a2b6c3d4f
                image_response:
                  summary: Image generation response (IMAGE æ¨¡æ)
                  value:
                    candidates:
                      - content:
                          parts:
                            - inline_data:
                                mime_type: image/png
                                data: iVBORw0KGgoAAAANSUhEUgAA...
                          role: model
                        finishReason: STOP
                        safetyRatings:
                          - category: HARM_CATEGORY_HATE_SPEECH
                            probability: NEGLIGIBLE
                    usageMetadata:
                      promptTokenCount: 24
                      candidatesTokenCount: 0
                      totalTokenCount: 24
                    modelVersion: gemini-3-flash-proview-001
                    responseId: 9e3f7b2a-4c8d-4f1e-6a9b-3d5c2f8e7a1b
                video_response:
                  summary: Video analysis response
                  value:
                    candidates:
                      - content:
                          parts:
                            - text: The video shows a sunset over the ocean, with waves gently rolling onto the beach. A person is walking along the shoreline...
                          role: model
                        finishReason: STOP
                    usageMetadata:
                      promptTokenCount: 156
                      candidatesTokenCount: 89
                      totalTokenCount: 245
                    modelVersion: gemini-3-flash
                    responseId: 1a2b3c4d-5e6f-7a8b-9c0d-1e2f3a4b5c6d
        '400':
          $ref: '#/components/responses/BadRequestError'
        '401':
          $ref: '#/components/responses/AuthenticationError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/InternalServerError'
  /v1beta/models/{model}:streamGenerateContent:
    post:
      summary: Generate content (streaming)
      description: |
        Generates a streamed response from the model given an input GenerateContentRequest.
        The response is returned as Server-Sent Events (SSE) for real-time streaming.

        Authentication uses Bearer token in Authorization header (compatible with your platform's OpenAI-style auth).
      operationId: streamGenerateContent
      x-speakeasy-name-override: streamGenerateContent
      tags:
        - Gemini
      security:
        - api_key: []
      parameters:
        - name: model
          in: path
          required: true
          description: |
            The model resource name in format models/{model}.
            Examples: models/gemini-3-flash, models/gemini-3-pro
          schema:
            type: string
            example: models/gemini-3-flash
        - name: alt
          in: query
          required: false
          description: Data format for the response (use 'sse' for server-sent events)
          schema:
            type: string
            enum:
              - sse
            default: sse
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/GeminiGenerateContentRequest'
            examples:
              simple_stream:
                summary: Simple streaming text generation
                value:
                  contents:
                    - parts:
                        - text: Tell me a story about a robot learning to paint.
              streaming_chat:
                summary: Streaming chat response
                value:
                  contents:
                    - role: user
                      parts:
                        - text: Explain quantum computing
                  generationConfig:
                    temperature: 0.8
                    maxOutputTokens: 1024
              streaming_with_images:
                summary: Streaming with image input
                value:
                  contents:
                    - parts:
                        - text: Describe this image in detail
                        - inline_data:
                            mime_type: image/jpeg
                            data: base64_encoded_image_data...
              streaming_with_system_instruction:
                summary: Streaming with system instruction
                value:
                  systemInstruction:
                    parts:
                      - text: You are a professional translator. Translate all text to French and maintain formal tone.
                  contents:
                    - parts:
                        - text: Write a business email about scheduling a meeting
                  generationConfig:
                    temperature: 0.3
                    maxOutputTokens: 512
              streaming_function_calling:
                summary: Streaming with function calling
                value:
                  contents:
                    - parts:
                        - text: Search for restaurants near me and get their ratings
                  tools:
                    - functionDeclarations:
                        - name: search_nearby_places
                          description: Search for places near a location
                          parameters:
                            type: object
                            properties:
                              place_type:
                                type: string
                                description: Type of place (restaurant, cafe, etc)
                              radius:
                                type: integer
                                description: Search radius in meters
                            required:
                              - place_type
                  toolConfig:
                    functionCallingConfig:
                      mode: ANY
              streaming_json_mode:
                summary: Streaming structured JSON output
                value:
                  contents:
                    - parts:
                        - text: Generate a product catalog with 5 items
                  generationConfig:
                    temperature: 0.5
                    responseMimeType: application/json
                    responseSchema:
                      type: object
                      properties:
                        products:
                          type: array
                          items:
                            type: object
                            properties:
                              name:
                                type: string
                              price:
                                type: number
                              category:
                                type: string
      responses:
        '200':
          description: Successful streaming response (Server-Sent Events)
          content:
            text/event-stream:
              schema:
                type: string
                description: |
                  Stream of Server-Sent Events, each containing a GeminiGenerateContentResponse JSON object.
                  Each chunk represents partial content as it's generated.
              examples:
                stream_chunks:
                  summary: Example stream chunks
                  value: |
                    data: {"candidates":[{"content":{"parts":[{"text":"Once"}],"role":"model"},"finishReason":""}],"usageMetadata":{"promptTokenCount":10,"candidatesTokenCount":1,"totalTokenCount":11}}

                    data: {"candidates":[{"content":{"parts":[{"text":" upon"}],"role":"model"},"finishReason":""}],"usageMetadata":{"promptTokenCount":10,"candidatesTokenCount":2,"totalTokenCount":12}}

                    data: {"candidates":[{"content":{"parts":[{"text":" a"}],"role":"model"},"finishReason":""}],"usageMetadata":{"promptTokenCount":10,"candidatesTokenCount":3,"totalTokenCount":13}}

                    data: {"candidates":[{"content":{"parts":[{"text":" time"}],"role":"model"},"finishReason":"STOP"}],"usageMetadata":{"promptTokenCount":10,"candidatesTokenCount":4,"totalTokenCount":14}}
        '400':
          $ref: '#/components/responses/BadRequestError'
        '401':
          $ref: '#/components/responses/AuthenticationError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/InternalServerError'
  /v1beta/models/{model}:embedContent:
    post:
      summary: Generate embeddings
      description: |
        Generates a text embedding vector from the input content using the specified embedding model.
        Supports different task types for optimized embeddings (retrieval, similarity, classification, etc.).

        Authentication uses Bearer token in Authorization header (compatible with your platform's OpenAI-style auth).
      operationId: embedContent
      x-speakeasy-name-override: embedContent
      tags:
        - Gemini
      security:
        - api_key: []
      parameters:
        - name: model
          in: path
          required: true
          description: |
            The embedding model resource name.
            Examples: models/text-embedding-005, models/embedding-001
          schema:
            type: string
            example: models/text-embedding-005
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/GeminiEmbedContentRequest'
            examples:
              simple_embedding:
                summary: Simple text embedding
                value:
                  content:
                    parts:
                      - text: What is the meaning of life?
              query_embedding:
                summary: Query embedding for retrieval
                value:
                  content:
                    parts:
                      - text: How do I reset my password?
                  taskType: RETRIEVAL_QUERY
              document_embedding:
                summary: Document embedding with title
                value:
                  content:
                    parts:
                      - text: To reset your password, go to Settings > Security > Password Reset. Click 'Reset Password' and follow the instructions sent to your email.
                  taskType: RETRIEVAL_DOCUMENT
                  title: Password Reset Guide
              semantic_similarity:
                summary: Embedding for semantic similarity
                value:
                  content:
                    parts:
                      - text: The quick brown fox jumps over the lazy dog
                  taskType: SEMANTIC_SIMILARITY
              reduced_dimensions:
                summary: Embedding with reduced dimensionality
                value:
                  content:
                    parts:
                      - text: Machine learning is a subset of artificial intelligence
                  taskType: CLASSIFICATION
                  outputDimensionality: 256
              code_retrieval:
                summary: Code retrieval query embedding
                value:
                  content:
                    parts:
                      - text: function to sort an array in javascript
                  taskType: CODE_RETRIEVAL_QUERY
              clustering:
                summary: Embedding for clustering analysis
                value:
                  content:
                    parts:
                      - text: Machine learning algorithms can be categorized into supervised, unsupervised, and reinforcement learning approaches
                  taskType: CLUSTERING
              question_answering:
                summary: Embedding for question answering
                value:
                  content:
                    parts:
                      - text: What are the health benefits of drinking green tea?
                  taskType: QUESTION_ANSWERING
              fact_verification:
                summary: Embedding for fact verification
                value:
                  content:
                    parts:
                      - text: The Great Wall of China is visible from space with the naked eye
                  taskType: FACT_VERIFICATION
      responses:
        '200':
          description: Successful response with embedding vector
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/GeminiEmbedContentResponse'
              examples:
                embedding_response:
                  summary: Embedding response example
                  value:
                    embedding:
                      values:
                        - 0.013168523
                        - -0.008711934
                        - -0.046782676
                        - 0.000699915
                        - -0.024826486
                        - 0.006124973
                        - -0.021250842
                        - 0.009423063
                        - -0.037530474
                        - 0.021392729
                full_dimension_response:
                  summary: Full dimension embedding (768 dimensions truncated for display)
                  value:
                    embedding:
                      values:
                        - 0.013168523
                        - -0.008711934
                        - -0.046782676
                        - 0.000699915
                        - -0.024826486
                        - 0.006124973
                        - -0.021250842
                        - 0.009423063
                        - -0.037530474
                        - 0.021392729
                        - 0.015234
                        - -0.012456
                        - 0.034567
        '400':
          $ref: '#/components/responses/BadRequestError'
        '401':
          $ref: '#/components/responses/AuthenticationError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/InternalServerError'
  /v1beta/models/{model}:batchGenerateContent:
    post:
      summary: Create async batch generation job
      description: |
        Creates an asynchronous batch job to process multiple generateContent requests.
        Returns a job object immediately. Results are available within 24 hours at 50% lower cost.
        Use GET /v1beta/batches/{name} to poll job status and retrieve results.
      operationId: batchGenerateContent
      x-speakeasy-name-override: batchGenerateContent
      tags:
        - Gemini
      security:
        - api_key: []
      parameters:
        - name: model
          in: path
          required: true
          description: Default model for all requests in the batch
          schema:
            type: string
            example: models/gemini-3-flash
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/GeminiBatchGenerateContentRequest'
            examples:
              inline_requests:
                summary: Inline requests (max 20MB)
                value:
                  batch:
                    display_name: my-batch-job
                    input_config:
                      requests:
                        requests:
                          - request:
                              contents:
                                - parts:
                                    - text: Write a haiku about the ocean
                            metadata:
                              key: req-1
                          - request:
                              contents:
                                - parts:
                                    - text: Explain quantum entanglement simply
                              generationConfig:
                                maxOutputTokens: 256
                            metadata:
                              key: req-2
              file_input:
                summary: File-based input (max 2GB)
                value:
                  batch:
                    display_name: large-batch-job
                    input_config:
                      file_name: files/abc123def456
              batch_image_analysis:
                summary: Batch image analysis requests
                value:
                  batch:
                    display_name: batch-image-analysis
                    input_config:
                      requests:
                        requests:
                          - request:
                              contents:
                                - parts:
                                    - text: What objects are in this image?
                                    - inline_data:
                                        mime_type: image/jpeg
                                        data: /9j/4AAQSkZJRgABAQAAAQABAAD...
                            metadata:
                              image_id: img_001
                          - request:
                              contents:
                                - parts:
                                    - text: Describe the colors and composition
                                    - inline_data:
                                        mime_type: image/png
                                        data: iVBORw0KGgoAAAANSUhEUgAA...
                            metadata:
                              image_id: img_002
              batch_json_output:
                summary: Batch with structured JSON output
                value:
                  batch:
                    display_name: batch-json-extraction
                    input_config:
                      requests:
                        requests:
                          - request:
                              contents:
                                - parts:
                                    - text: Extract product information from this description
                              generationConfig:
                                responseMimeType: application/json
                                responseSchema:
                                  type: object
                                  properties:
                                    product_name:
                                      type: string
                                    price:
                                      type: number
                                    features:
                                      type: array
                                      items:
                                        type: string
                            metadata:
                              doc_id: doc_001
                          - request:
                              contents:
                                - parts:
                                    - text: List all key specifications in JSON format
                              generationConfig:
                                responseMimeType: application/json
                            metadata:
                              doc_id: doc_002
              batch_with_system_instruction:
                summary: Batch with system instruction
                value:
                  batch:
                    display_name: batch-translation-job
                    input_config:
                      requests:
                        requests:
                          - request:
                              systemInstruction:
                                parts:
                                  - text: You are a professional translator. Translate to Spanish.
                              contents:
                                - parts:
                                    - text: Hello, how are you today?
                            metadata:
                              text_id: text_001
                          - request:
                              systemInstruction:
                                parts:
                                  - text: You are a professional translator. Translate to French.
                              contents:
                                - parts:
                                    - text: Good morning, welcome to our service
                            metadata:
                              text_id: text_002
              batch_with_tools:
                summary: Batch with function calling
                value:
                  batch:
                    display_name: batch-function-calling
                    input_config:
                      requests:
                        requests:
                          - request:
                              contents:
                                - parts:
                                    - text: What's the weather in Tokyo?
                              tools:
                                - functionDeclarations:
                                    - name: get_current_weather
                                      description: Get current weather
                                      parameters:
                                        type: object
                                        properties:
                                          location:
                                            type: string
                                        required:
                                          - location
                              toolConfig:
                                functionCallingConfig:
                                  mode: AUTO
                            metadata:
                              query_id: weather_001
                          - request:
                              contents:
                                - parts:
                                    - text: Calculate the total cost of 5 items at $29.99 each
                              tools:
                                - functionDeclarations:
                                    - name: calculate
                                      description: Perform calculations
                                      parameters:
                                        type: object
                                        properties:
                                          expression:
                                            type: string
                            metadata:
                              query_id: calc_001
      responses:
        '200':
          description: Batch job created successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/GeminiBatchGenerateContentResponse'
              examples:
                job_created:
                  summary: Job created and pending
                  value:
                    name: batches/123456789
                    display_name: my-batch-job
                    state: JOB_STATE_PENDING
                    create_time: '2026-01-29T10:00:00Z'
                    update_time: '2026-01-29T10:00:00Z'
                    input_config:
                      requests:
                        requests:
                          - request:
                              contents:
                                - parts:
                                    - text: Write a haiku about the ocean
        '400':
          $ref: '#/components/responses/BadRequestError'
        '401':
          $ref: '#/components/responses/AuthenticationError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/InternalServerError'
components:
  securitySchemes:
    api_key:
      type: http
      scheme: bearer
      bearerFormat: API Key
  schemas:
    GeminiBatchGenerateContentRequest:
      type: object
      description: Request to create an async batch generation job
      properties:
        batch:
          type: object
          properties:
            display_name:
              type: string
              description: Human-readable name for this batch job
            input_config:
              $ref: '#/components/schemas/GeminiInputConfig'
          required:
            - input_config
      required:
        - batch
    GeminiBatchGenerateContentResponse:
      type: object
      description: Response from batch job creation (returns job metadata)
      allOf:
        - $ref: '#/components/schemas/GeminiBatch'
    GeminiBatch:
      type: object
      description: Batch job object representing an async batch processing task
      properties:
        name:
          type: string
          description: Batch job identifier
          example: batches/123456789
          readOnly: true
        display_name:
          type: string
          description: User-defined label for this batch
          example: my-batch-job
        state:
          $ref: '#/components/schemas/GeminiJobState'
          readOnly: true
        create_time:
          type: string
          format: date-time
          description: Job creation timestamp
          readOnly: true
        update_time:
          type: string
          format: date-time
          description: Last update timestamp
          readOnly: true
        input_config:
          $ref: '#/components/schemas/GeminiInputConfig'
        output_config:
          $ref: '#/components/schemas/GeminiOutputConfig'
          readOnly: true
        error:
          $ref: '#/components/schemas/GeminiBatchError'
          readOnly: true
        batch_stats:
          $ref: '#/components/schemas/GeminiBatchStats'
          readOnly: true
    Model:
      type: object
      required:
        - id
        - object
        - created
        - owned_by
      properties:
        id:
          type: string
          description: Model identifier
        object:
          type: string
          const: model
        created:
          type: integer
          description: Creation timestamp
        owned_by:
          type: string
          description: Model owner
    ModelListResponse:
      type: object
      required:
        - object
        - data
      properties:
        object:
          type: string
          const: list
        data:
          type: array
          items:
            $ref: '#/components/schemas/Model'
    R9SError:
      type: object
      required:
        - error
      properties:
        error:
          type: object
          required:
            - message
            - type
          properties:
            message:
              type: string
              description: Error message
            type:
              type: string
              description: Error type
            code:
              anyOf:
                - type: string
                - type: 'null'
              description: Error code
            param:
              type: string
              description: Related parameter
        status:
          type: integer
          description: HTTP status code
    AuthenticationError:
      allOf:
        - $ref: '#/components/schemas/R9SError'
        - type: object
          properties:
            status:
              enum:
                - 401
    PermissionDeniedError:
      allOf:
        - $ref: '#/components/schemas/R9SError'
        - type: object
          properties:
            status:
              enum:
                - 403
    InternalServerError:
      allOf:
        - $ref: '#/components/schemas/R9SError'
        - type: object
          properties:
            status:
              enum:
                - 500
    NotFoundError:
      allOf:
        - $ref: '#/components/schemas/R9SError'
        - type: object
          properties:
            status:
              enum:
                - 404
    AnthropicTextContent:
      type: object
      required:
        - type
        - text
      properties:
        type:
          type: string
          const: text
        text:
          type: string
    AnthropicImageSourceBase64:
      type: object
      required:
        - type
        - media_type
        - data
      properties:
        type:
          type: string
          const: base64
        media_type:
          type: string
          enum:
            - image/jpeg
            - image/png
            - image/gif
            - image/webp
          description: MIME type of the image
        data:
          type: string
          description: Base64-encoded image data
    AnthropicImageSourceUrl:
      type: object
      required:
        - type
        - url
      properties:
        type:
          type: string
          const: url
        url:
          type: string
          format: uri
          description: URL of the image to fetch
    AnthropicImageSource:
      oneOf:
        - $ref: '#/components/schemas/AnthropicImageSourceBase64'
        - $ref: '#/components/schemas/AnthropicImageSourceUrl'
      discriminator:
        propertyName: type
        mapping:
          base64: '#/components/schemas/AnthropicImageSourceBase64'
          url: '#/components/schemas/AnthropicImageSourceUrl'
    AnthropicImageContent:
      type: object
      required:
        - type
        - source
      properties:
        type:
          type: string
          const: image
        source:
          $ref: '#/components/schemas/AnthropicImageSource'
    AnthropicDocumentSourceBase64:
      type: object
      required:
        - type
        - media_type
        - data
      properties:
        type:
          type: string
          const: base64
        media_type:
          type: string
          enum:
            - application/pdf
            - text/plain
          description: Document MIME type
        data:
          type: string
          description: Base64-encoded document data
    AnthropicDocumentSourceUrl:
      type: object
      required:
        - type
        - url
      properties:
        type:
          type: string
          const: url
        url:
          type: string
          format: uri
          description: URL of the document to fetch
    AnthropicDocumentSource:
      oneOf:
        - $ref: '#/components/schemas/AnthropicDocumentSourceBase64'
        - $ref: '#/components/schemas/AnthropicDocumentSourceUrl'
      discriminator:
        propertyName: type
        mapping:
          base64: '#/components/schemas/AnthropicDocumentSourceBase64'
          url: '#/components/schemas/AnthropicDocumentSourceUrl'
    AnthropicDocumentContent:
      type: object
      required:
        - type
        - source
      properties:
        type:
          type: string
          const: document
          description: Document content type (PDFs, text files, etc.)
        source:
          $ref: '#/components/schemas/AnthropicDocumentSource'
    AnthropicThinkingContent:
      type: object
      required:
        - type
        - thinking
      properties:
        type:
          type: string
          const: thinking
          description: Extended thinking output content
        thinking:
          type: string
          description: The model's thinking process/reasoning
        signature:
          type: string
          description: Cryptographic signature for thinking content verification
    AnthropicToolUseContent:
      type: object
      required:
        - type
        - id
        - name
        - input
      properties:
        type:
          type: string
          const: tool_use
        id:
          type: string
          description: Unique identifier for this tool use
        name:
          type: string
          description: Name of the tool being called
        input:
          type: object
          additionalProperties: true
          description: Input parameters for the tool
    AnthropicToolResultContent:
      type: object
      required:
        - type
        - tool_use_id
        - content
      properties:
        type:
          type: string
          const: tool_result
        tool_use_id:
          type: string
          description: ID of the tool use this result corresponds to
        content:
          type: string
          description: Result of the tool execution
    AnthropicToolContent:
      oneOf:
        - $ref: '#/components/schemas/AnthropicToolUseContent'
        - $ref: '#/components/schemas/AnthropicToolResultContent'
      discriminator:
        propertyName: type
        mapping:
          tool_use: '#/components/schemas/AnthropicToolUseContent'
          tool_result: '#/components/schemas/AnthropicToolResultContent'
    AnthropicContent:
      oneOf:
        - $ref: '#/components/schemas/AnthropicTextContent'
        - $ref: '#/components/schemas/AnthropicImageContent'
        - $ref: '#/components/schemas/AnthropicDocumentContent'
        - $ref: '#/components/schemas/AnthropicThinkingContent'
        - $ref: '#/components/schemas/AnthropicToolContent'
    AnthropicMessageMessage:
      type: object
      required:
        - role
        - content
      properties:
        role:
          type: string
          enum:
            - user
            - assistant
          description: Role of the message sender (user or assistant)
        content:
          oneOf:
            - type: array
              items:
                $ref: '#/components/schemas/AnthropicContent'
              description: Array of content blocks for user messages or assistant responses
            - type: string
              description: Simple text content (deprecated but supported for backward compatibility)
          description: Message content - can be array of content blocks or string
    AnthropicInputSchema:
      type: object
      required:
        - type
      properties:
        type:
          type: string
          const: object
        properties:
          type: object
        required:
          type: array
          items:
            type: string
    AnthropicTool:
      type: object
      required:
        - name
        - input_schema
      properties:
        name:
          type: string
        description:
          type: string
        input_schema:
          $ref: '#/components/schemas/AnthropicInputSchema'
    AnthropicMessageRequest:
      type: object
      required:
        - model
        - messages
      properties:
        model:
          type: string
          description: Claude model name
        messages:
          type: array
          items:
            $ref: '#/components/schemas/AnthropicMessageMessage'
          description: Messages list, first message must be a user message
        system:
          type: string
          description: System prompt
        max_tokens:
          type: integer
          minimum: 1
          description: |
            Maximum number of output tokens (optional).
            If not provided, the relay service or API may use a default value.
            Different models have different maximum values.
        stop_sequences:
          type: array
          items:
            type: string
          description: Stop sequences
        stream:
          type: boolean
          default: false
        temperature:
          type: number
          minimum: 0
          maximum: 1
        top_p:
          type: number
          minimum: 0
          maximum: 1
        top_k:
          type: integer
          minimum: 1
          description: Top-k sampling parameter. Only sample from the top K options for each subsequent token.
        tools:
          type: array
          items:
            $ref: '#/components/schemas/AnthropicTool'
        tool_choice:
          oneOf:
            - type: string
              enum:
                - none
                - auto
                - any
            - type: object
              properties:
                type:
                  type: string
                  const: tool
                name:
                  type: string
        metadata:
          type: object
          description: |
            An object describing metadata about the request. Can be used for tracking, identification, or filtering purposes.
            Common use cases: user_id, session_id, request_id, etc.
          additionalProperties: true
        thinking:
          type: object
          description: |
            Configuration for extended thinking (Claude 3.7+). When enabled, the model will spend more time thinking before responding.
          properties:
            type:
              type: string
              enum:
                - enabled
                - disabled
              default: disabled
              description: Whether to enable extended thinking
            budget_tokens:
              type: integer
              minimum: 1000
              maximum: 10000
              description: Maximum number of tokens to use for thinking (1000-10000)
        service_tier:
          type: string
          enum:
            - auto
            - standard_only
          default: auto
          description: |
            Service tier for request processing:
            - auto: Automatically select between standard and priority capacity
            - standard_only: Only use standard capacity (may have longer wait times during high load)
    AnthropicMessageResponse:
      type: object
      required:
        - id
        - type
        - role
        - content
        - model
        - stop_reason
        - usage
      properties:
        id:
          type: string
        type:
          type: string
          const: message
        role:
          type: string
          const: assistant
        content:
          type: array
          items:
            $ref: '#/components/schemas/AnthropicContent'
        model:
          type: string
        stop_reason:
          anyOf:
            - type: string
              enum:
                - end_turn
                - max_tokens
                - stop_sequence
                - tool_use
                - pause_turn
                - refusal
            - type: 'null'
          description: |
            Reason why the model stopped:
            - end_turn: Natural completion
            - max_tokens: Hit max_tokens limit
            - stop_sequence: Hit a stop sequence
            - tool_use: Model wants to use a tool
            - pause_turn: Long-running task paused (extended thinking)
            - refusal: Content policy violation
        stop_sequence:
          anyOf:
            - type: string
            - type: 'null'
        usage:
          type: object
          required:
            - input_tokens
            - output_tokens
          properties:
            input_tokens:
              type: integer
              description: Number of input tokens used
            cache_creation_input_tokens:
              type: integer
              description: Number of input tokens used to create cache entries (only present if prompt caching is used)
            cache_read_input_tokens:
              type: integer
              description: Number of input tokens read from cache (only present if prompt caching is used)
            output_tokens:
              type: integer
              description: Number of output tokens generated
    AnthropicMessageStart:
      type: object
      required:
        - type
        - message
      properties:
        type:
          type: string
          const: message_start
        message:
          type: object
          required:
            - id
            - type
            - role
            - content
            - model
            - stop_reason
            - stop_sequence
            - usage
          properties:
            id:
              type: string
            type:
              type: string
              const: message
            role:
              type: string
              const: assistant
            content:
              type: array
              items:
                type: object
            model:
              type: string
            stop_reason:
              anyOf:
                - type: string
                - type: 'null'
            stop_sequence:
              anyOf:
                - type: string
                - type: 'null'
            usage:
              type: object
              required:
                - input_tokens
                - output_tokens
              properties:
                input_tokens:
                  type: integer
                output_tokens:
                  type: integer
    AnthropicContentBlockStart:
      type: object
      required:
        - type
        - index
        - content_block
      properties:
        type:
          type: string
          const: content_block_start
        index:
          type: integer
        content_block:
          type: object
          required:
            - type
          properties:
            type:
              type: string
              enum:
                - text
                - tool_use
            text:
              type: string
            id:
              type: string
            name:
              type: string
            input:
              type: object
    AnthropicContentBlockDelta:
      type: object
      required:
        - type
        - index
        - delta
      properties:
        type:
          type: string
          const: content_block_delta
        index:
          type: integer
        delta:
          type: object
          properties:
            type:
              type: string
              enum:
                - text_delta
                - input_json_delta
            text:
              type: string
            partial_json:
              type: string
    AnthropicContentBlockStop:
      type: object
      required:
        - type
        - index
      properties:
        type:
          type: string
          const: content_block_stop
        index:
          type: integer
        content_block:
          type: object
          description: Optional content block metadata
    AnthropicMessageDelta:
      type: object
      required:
        - type
        - delta
        - usage
      properties:
        type:
          type: string
          const: message_delta
        delta:
          type: object
          properties:
            stop_reason:
              anyOf:
                - type: string
                - type: 'null'
        usage:
          type: object
          properties:
            output_tokens:
              type: integer
    AnthropicStreamMessageStop:
      type: object
      required:
        - type
      properties:
        type:
          type: string
          const: message_stop
    AnthropicPing:
      type: object
      required:
        - type
      properties:
        type:
          type: string
          const: ping
      description: SSE heartbeat event to keep connection alive
    AnthropicStreamEvent:
      oneOf:
        - $ref: '#/components/schemas/AnthropicMessageStart'
        - $ref: '#/components/schemas/AnthropicContentBlockStart'
        - $ref: '#/components/schemas/AnthropicContentBlockDelta'
        - $ref: '#/components/schemas/AnthropicContentBlockStop'
        - $ref: '#/components/schemas/AnthropicMessageDelta'
        - $ref: '#/components/schemas/AnthropicStreamMessageStop'
        - $ref: '#/components/schemas/AnthropicPing'
      discriminator:
        propertyName: type
        mapping:
          message_start: '#/components/schemas/AnthropicMessageStart'
          content_block_start: '#/components/schemas/AnthropicContentBlockStart'
          content_block_delta: '#/components/schemas/AnthropicContentBlockDelta'
          content_block_stop: '#/components/schemas/AnthropicContentBlockStop'
          message_delta: '#/components/schemas/AnthropicMessageDelta'
          message_stop: '#/components/schemas/AnthropicStreamMessageStop'
          ping: '#/components/schemas/AnthropicPing'
    BadRequestError:
      allOf:
        - $ref: '#/components/schemas/R9SError'
        - type: object
          properties:
            status:
              enum:
                - 400
    ConflictError:
      allOf:
        - $ref: '#/components/schemas/R9SError'
        - type: object
          properties:
            status:
              enum:
                - 409
      description: |
        Resource conflict error. Reserved for future use cases:
        - Duplicate resource creation
        - Concurrent modification conflicts
        - State conflicts in background tasks
    UnprocessableEntityError:
      allOf:
        - $ref: '#/components/schemas/R9SError'
        - type: object
          properties:
            status:
              enum:
                - 422
    RateLimitError:
      allOf:
        - $ref: '#/components/schemas/R9SError'
        - type: object
          properties:
            status:
              enum:
                - 429
    ServiceUnavailableError:
      allOf:
        - $ref: '#/components/schemas/R9SError'
        - type: object
          properties:
            status:
              enum:
                - 502
                - 503
    ImageURL:
      type: object
      required:
        - url
      properties:
        url:
          type: string
        detail:
          type: string
          enum:
            - auto
            - low
            - high
    MessageContent:
      type: object
      required:
        - type
      properties:
        type:
          type: string
          enum:
            - text
            - image_url
        text:
          type: string
        image_url:
          $ref: '#/components/schemas/ImageURL'
    FunctionCall:
      type: object
      required:
        - name
      properties:
        name:
          type: string
        arguments:
          type: string
    ToolCall:
      type: object
      required:
        - id
        - type
        - function
      properties:
        id:
          type: string
        type:
          type: string
        function:
          $ref: '#/components/schemas/FunctionCall'
    Message:
      type: object
      required:
        - role
      description: |
        Message object. Note: Different API endpoints have different field requirements and support.

        **Field support:**
        - /v1/chat/completions: Supports all fields (tool_calls, tool_call_id, etc.)
        - /v1/responses: Only supports basic fields (role, content, name); does not support tool_calls and tool_call_id

        **content field requirements:**
        - /v1/chat/completions: When tool_calls is present, content can be omitted or null
        - /v1/responses: content field is always required and cannot be null; tool_calls field is not supported
      properties:
        role:
          type: string
          enum:
            - system
            - user
            - assistant
            - tool
          description: Message role
        content:
          anyOf:
            - type: string
            - type: array
              items:
                $ref: '#/components/schemas/MessageContent'
            - type: 'null'
          description: |
            Message content. Can be null when assistant message contains tool_calls.
            - user/system messages: Required, contains text or multimodal content
            - assistant messages: Optional when tool_calls is present; can be null or omitted
            - tool messages: Required, contains tool return results (usually JSON string)

            **Important:** In /v1/responses API, content field must exist and cannot be null.
            For /v1/chat/completions, content can be null when tool_calls is present.
        name:
          type: string
          description: Sender name
        reasoning_content:
          type: string
          description: Reasoning content
        tool_calls:
          type: array
          items:
            $ref: '#/components/schemas/ToolCall'
          description: Tool calls list
        tool_call_id:
          type: string
          description: Tool call ID
    Audio:
      type: object
      properties:
        voice:
          type: string
          enum:
            - alloy
            - echo
            - fable
            - onyx
            - nova
            - shimmer
          description: Voice type for audio output
        format:
          type: string
          enum:
            - mp3
            - opus
            - aac
            - flac
            - wav
            - pcm
          description: Audio output format
    JsonSchema:
      type: object
      properties:
        name:
          type: string
        description:
          type: string
        schema:
          type: object
          additionalProperties: true
    ResponseFormat:
      type: object
      properties:
        type:
          type: string
          enum:
            - text
            - json_object
            - json_schema
        json_schema:
          $ref: '#/components/schemas/JsonSchema'
    StreamOptions:
      type: object
      properties:
        include_usage:
          type: boolean
          description: Whether to include usage statistics
    Tool:
      type: object
      required:
        - type
        - function
      description: |
        Tool definition (nested format). Used for /v1/chat/completions and other endpoints.
        Format: { "type": "function", "function": { "name": "...", "description": "...", "parameters": {...} } }
      properties:
        type:
          type: string
          enum:
            - function
          description: Tool type, currently only supports function
        function:
          type: object
          required:
            - name
          properties:
            name:
              type: string
              description: Function name
            description:
              type: string
              description: Function description, helps model understand when to call this function
            parameters:
              type: object
              description: Function parameter definition in JSON Schema format
              additionalProperties: true
    ChatCompletionRequest:
      type: object
      required:
        - model
        - messages
      properties:
        model:
          type: string
          description: Model name
        messages:
          type: array
          items:
            $ref: '#/components/schemas/Message'
          description: Messages list
        frequency_penalty:
          type: number
          minimum: -2
          maximum: 2
        logit_bias:
          type: object
          additionalProperties:
            type: number
        logprobs:
          type: boolean
          description: When true, stream must be false (OpenAI constraint)
        top_logprobs:
          type: integer
          minimum: 0
          maximum: 20
        max_tokens:
          type: integer
          minimum: 1
        'n':
          type: integer
          minimum: 1
          maximum: 128
          description: Number of chat completion choices to generate
        modalities:
          type: array
          items:
            type: string
            enum:
              - text
              - audio
          description: Output modality types. Use ["text", "audio"] for audio output
        audio:
          $ref: '#/components/schemas/Audio'
          description: Audio output configuration (when modalities includes audio)
        presence_penalty:
          type: number
          minimum: -2
          maximum: 2
        response_format:
          $ref: '#/components/schemas/ResponseFormat'
        seed:
          type: integer
        service_tier:
          type: string
          enum:
            - auto
            - default
        stop:
          oneOf:
            - type: string
            - type: array
              items:
                type: string
        stream:
          type: boolean
          default: false
        stream_options:
          $ref: '#/components/schemas/StreamOptions'
        temperature:
          type: number
          minimum: 0
          maximum: 2
        top_p:
          type: number
          minimum: 0
          maximum: 1
        top_k:
          type: integer
          minimum: 1
          description: Top-k sampling parameter (non-OpenAI standard, model-specific)
        tools:
          type: array
          items:
            $ref: '#/components/schemas/Tool'
        tool_choice:
          oneOf:
            - type: string
              enum:
                - none
                - auto
                - required
            - type: object
              properties:
                type:
                  type: string
                  const: function
                function:
                  type: object
                  properties:
                    name:
                      type: string
        parallel_tool_calls:
          type: boolean
          description: Whether to enable parallel function calling during tool use. Only valid when tools are specified.
        user:
          type: string
          description: Unique identifier representing end-user for abuse monitoring
        reasoning_effort:
          type: string
          enum:
            - low
            - medium
            - high
          description: Reasoning effort level for o1 series models (low, medium, high)
        max_completion_tokens:
          type: integer
          minimum: 1
          description: Maximum number of tokens to generate in the completion (alternative to max_tokens, more precise)
        store:
          type: boolean
          description: Whether to store the output for use in model distillation or evals
        metadata:
          type: object
          additionalProperties: true
          description: Custom metadata to attach to the request for tracking purposes
    ChatCompletionChoice:
      type: object
      required:
        - index
        - message
        - finish_reason
      properties:
        index:
          type: integer
        message:
          $ref: '#/components/schemas/Message'
        finish_reason:
          type: string
          enum:
            - stop
            - length
            - tool_calls
            - content_filter
        logprobs:
          type: object
    Usage:
      type: object
      required:
        - prompt_tokens
        - completion_tokens
        - total_tokens
      properties:
        prompt_tokens:
          type: integer
          description: Number of tokens in the prompt (input)
        prompt_tokens_details:
          type: object
          description: Details about prompt tokens
          properties:
            cached_tokens:
              type: integer
              description: Number of cached tokens
            audio_tokens:
              type: integer
              description: Number of audio tokens in the prompt
        completion_tokens:
          type: integer
          description: Number of tokens in the completion (output)
        completion_tokens_details:
          type: object
          description: Details about completion tokens
          properties:
            reasoning_tokens:
              type: integer
              description: Number of reasoning tokens
            audio_tokens:
              type: integer
              description: Number of audio tokens
            accepted_prediction_tokens:
              type: integer
              description: Number of accepted prediction tokens
            rejected_prediction_tokens:
              type: integer
              description: Number of rejected prediction tokens
        total_tokens:
          type: integer
          description: Total number of tokens (prompt + completion)
    ChatCompletionResponse:
      type: object
      required:
        - id
        - object
        - created
        - model
        - choices
      properties:
        id:
          type: string
        object:
          type: string
          const: chat.completion
        created:
          type: integer
        model:
          type: string
        choices:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionChoice'
        usage:
          $ref: '#/components/schemas/Usage'
        system_fingerprint:
          type: string
    ChatCompletionStreamDelta:
      type: object
      properties:
        role:
          type: string
          enum:
            - system
            - user
            - assistant
        content:
          type: string
        tool_calls:
          type: array
          items:
            $ref: '#/components/schemas/ToolCall'
        reasoning_content:
          type: string
    ChatCompletionStreamChoice:
      type: object
      required:
        - index
        - delta
      properties:
        index:
          type: integer
        delta:
          $ref: '#/components/schemas/ChatCompletionStreamDelta'
        finish_reason:
          anyOf:
            - type: string
              enum:
                - stop
                - length
                - tool_calls
                - content_filter
            - type: 'null'
        logprobs:
          type: object
    ChatCompletionStreamEvent:
      description: Chat completion chunk event (data payload for SSE stream)
      type: object
      required:
        - id
        - object
        - created
        - model
        - choices
      x-speakeasy-unknown-values: allow
      properties:
        id:
          type: string
        object:
          type: string
          const: chat.completion.chunk
        created:
          type: integer
          description: Unix timestamp
        model:
          type: string
        choices:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionStreamChoice'
          description: Array of completion choices. May be empty in the final chunk when only usage is returned.
        system_fingerprint:
          type: string
        usage:
          $ref: '#/components/schemas/Usage'
          description: Usage information (only present in the last chunk when stream_options.include_usage is true)
    ResponseTool:
      type: object
      required:
        - type
        - name
      description: |
        Tool definition (flat format). Dedicated for /v1/responses endpoint.
        Format: { "type": "function", "name": "...", "description": "...", "parameters": {...} }
      properties:
        type:
          type: string
          enum:
            - function
          description: Tool type, currently only supports function
        name:
          type: string
          description: Function name
        description:
          type: string
          description: Function description, helps model understand when to call this function
        parameters:
          type: object
          description: Function parameter definition in JSON Schema format
          additionalProperties: true
          properties:
            type:
              type: string
              enum:
                - object
            properties:
              type: object
              additionalProperties: true
            required:
              type: array
              items:
                type: string
    ToolChoice:
      type: object
      required:
        - type
        - function
      description: Specify specific tool selection
      properties:
        type:
          type: string
          const: function
          description: Tool type
        function:
          type: object
          required:
            - name
          properties:
            name:
              type: string
              description: Function name to call
    ResponseRequest:
      type: object
      required:
        - model
        - input
      properties:
        model:
          type: string
          description: Model name
        input:
          oneOf:
            - type: string
            - type: array
              items:
                $ref: '#/components/schemas/Message'
          description: |
            Input content, required parameter. Can be:
            - String: Single text input
            - Message array: Structured conversation history

            **Important limitations:**
            - Messages only support basic fields (role, content, name)
            - Does not support tool_calls, tool_call_id and other tool-related fields
            - content field is required and cannot be null
            - To use tools, define them in the top-level tools parameter; model will call them on first response

            Note: Responses API has deprecated messages parameter, now uses input parameter uniformly
        instructions:
          type: string
          description: System-level instructions to guide model behavior and response style (similar to system message)
        temperature:
          type: number
          minimum: 0
          maximum: 2
          description: Controls output randomness, higher values mean more random
        top_p:
          type: number
          minimum: 0
          maximum: 1
          description: Nucleus sampling parameter, controls output diversity
        max_output_tokens:
          type: integer
          minimum: 1
          description: Maximum number of tokens to generate
        stream:
          type: boolean
          default: false
          description: Whether to enable streaming
        modalities:
          type: array
          items:
            type: string
            enum:
              - text
              - audio
          description: Response modality types
        tools:
          type: array
          items:
            $ref: '#/components/schemas/ResponseTool'
          description: Available tools list (using flat format)
        tool_choice:
          oneOf:
            - type: string
              enum:
                - none
                - auto
                - required
            - $ref: '#/components/schemas/ToolChoice'
          description: Tool selection strategy
        parallel_tool_calls:
          type: boolean
          default: true
          description: Whether to enable parallel function calling during tool use. When false, ensures exactly zero or one tool is called.
        text:
          type: object
          description: Text output configuration
          properties:
            format:
              type: object
              description: |
                An object specifying the format that the model must output. Setting to { "type": "json_schema", "name": "...", "schema": {...} } enables Structured Outputs which ensures the model will match your supplied JSON schema.
                Setting to { "type": "json_object" } enables JSON mode, which ensures the model generates valid JSON.
              properties:
                type:
                  type: string
                  enum:
                    - text
                    - json_object
                    - json_schema
                  description: The type of response format
                name:
                  type: string
                  description: Name for the schema (required when type is json_schema)
                schema:
                  type: object
                  description: JSON schema definition for structured outputs
                  additionalProperties: true
                strict:
                  type: boolean
                  description: Whether to enforce strict schema matching
            verbosity:
              type: string
              enum:
                - low
                - medium
                - high
              description: Verbosity level for the text output
        previous_response_id:
          type: string
          description: |
            The ID of a previous response to continue the conversation from. This allows you to chain responses together and maintain conversation state.
            When using previous_response_id, the model will automatically have access to all previously produced reasoning items and conversation history.
        store:
          type: boolean
          default: true
          description: |
            Whether to store the generated model response for later retrieval via API.
            Defaults to true. Set to false to disable storage (required for ZDR organizations).
        background:
          type: boolean
          default: false
          description: Whether to run the model response in the background asynchronously. Useful for long-running tasks.
        reasoning:
          type: object
          description: Configuration for reasoning models (e.g., o1, o3, gpt-5). Controls how the model uses reasoning tokens to "think" through the problem.
          properties:
            effort:
              type: string
              enum:
                - none
                - minimal
                - low
                - medium
                - high
                - xhigh
              description: The effort level for reasoning (none/minimal=fast, low/medium=balanced, high/xhigh=thorough)
            summary:
              type: string
              description: Summary of reasoning approach
        truncation:
          type: string
          enum:
            - auto
            - disabled
          default: disabled
          description: |
            The truncation strategy to use for the model response.
            - auto: If input exceeds context window, truncate by dropping items from beginning
            - disabled: Request fails with 400 error if input exceeds context window (default)
        stop:
          oneOf:
            - type: string
            - type: array
              items:
                type: string
          description: Up to 4 sequences where the API will stop generating further tokens
        metadata:
          type: object
          additionalProperties: true
          description: Additional metadata for tracking and organization purposes
    ResponseOutputItem:
      type: object
      required:
        - id
        - type
      properties:
        id:
          type: string
          description: Unique identifier for output item
        type:
          type: string
          enum:
            - message
            - function_call
            - reasoning
          description: Output type (message for final response, function_call for tool calls, reasoning for reasoning trace)
        status:
          type: string
          enum:
            - completed
            - in_progress
            - incomplete
          description: Output status
        role:
          type: string
          enum:
            - user
            - assistant
          description: Message role
        content:
          type: array
          description: Content array
          items:
            type: object
            properties:
              type:
                type: string
                enum:
                  - text
                  - refusal
                  - output_text
                  - reasoning_text
                description: Content type (text for messages, output_text for responses, reasoning_text for reasoning traces, refusal for safety refusals)
              text:
                type: string
                description: Text content
              refusal:
                type: string
                description: Refusal content
              annotations:
                type: array
                description: Content annotations
              logprobs:
                type: array
                description: Log probabilities
        call_id:
          type: string
          description: Function call ID
        name:
          type: string
          description: Function name
        arguments:
          type: string
          description: Function arguments (JSON string)
        output:
          type: string
          description: Function output
        summary:
          anyOf:
            - type: string
            - type: array
            - type: 'null'
          description: Natural-language summary of reasoning (for reasoning type), can be string or array
        encrypted_content:
          anyOf:
            - type: string
            - type: 'null'
          description: Encrypted reasoning tokens for stateless workflows (for reasoning type)
    ResponseUsage:
      type: object
      required:
        - input_tokens
        - output_tokens
        - total_tokens
      properties:
        input_tokens:
          type: integer
          description: Number of tokens in the input
        input_tokens_details:
          type: object
          description: Details about input tokens
          properties:
            cached_tokens:
              type: integer
              description: Number of cached tokens
        output_tokens:
          type: integer
          description: Number of tokens in the output
        output_tokens_details:
          type: object
          description: Details about output tokens
          properties:
            reasoning_tokens:
              type: integer
              description: Number of reasoning tokens
        total_tokens:
          type: integer
          description: Total number of tokens (input + output)
    ResponseObject:
      type: object
      required:
        - id
        - object
        - created_at
        - status
        - model
      properties:
        id:
          type: string
          description: Unique identifier for the response
        object:
          type: string
          const: response
        created_at:
          type: integer
          description: Unix timestamp when the response was created
        status:
          type: string
          enum:
            - in_progress
            - completed
            - incomplete
            - failed
            - cancelled
          description: The status of the response
        background:
          type: boolean
          description: Whether the response is running in the background
        billing:
          type: object
          description: Billing information
          properties:
            payer:
              type: string
              enum:
                - developer
                - organization
              description: Who is paying for this response
        completed_at:
          anyOf:
            - type: integer
            - type: 'null'
          description: Unix timestamp when the response was completed
        error:
          anyOf:
            - type: object
            - type: 'null'
          description: Error information if the response failed
        incomplete_details:
          anyOf:
            - type: object
            - type: 'null'
          description: Details about why the response is incomplete
        instructions:
          type: string
          description: System-level instructions that guided the model's behavior
        max_output_tokens:
          type: integer
          description: Maximum number of tokens to generate
        max_tool_calls:
          anyOf:
            - type: integer
            - type: 'null'
          description: Maximum number of tool calls allowed
        model:
          type: string
          description: The model used for the response
        output:
          type: array
          items:
            $ref: '#/components/schemas/ResponseOutputItem'
          description: Array of output items produced by the model
        parallel_tool_calls:
          type: boolean
          description: Whether parallel tool calls are enabled
        previous_response_id:
          anyOf:
            - type: string
            - type: 'null'
          description: ID of the previous response in a chain
        prompt_cache_key:
          anyOf:
            - type: string
            - type: 'null'
          description: Key for prompt caching
        prompt_cache_retention:
          anyOf:
            - type: string
            - type: 'null'
          description: Prompt cache retention policy
        reasoning:
          type: object
          description: Reasoning configuration
          properties:
            effort:
              anyOf:
                - type: string
                  enum:
                    - none
                    - minimal
                    - low
                    - medium
                    - high
                    - xhigh
                - type: 'null'
              description: Reasoning effort level (none/minimal for fast, low/medium for balanced, high/xhigh for thorough)
            summary:
              anyOf:
                - type: string
                - type: 'null'
              description: Summary of reasoning
        safety_identifier:
          anyOf:
            - type: string
            - type: 'null'
          description: Safety identifier for the response
        service_tier:
          type: string
          enum:
            - auto
            - default
          description: Service tier used
        store:
          type: boolean
          description: Whether to store the response
        temperature:
          type: number
          description: Temperature parameter used
        text:
          type: object
          description: Text format configuration
          properties:
            format:
              type: object
              properties:
                type:
                  type: string
                  enum:
                    - text
                    - json_object
                    - json_schema
            verbosity:
              type: string
              enum:
                - low
                - medium
                - high
              description: Verbosity level
        tool_choice:
          oneOf:
            - type: string
              enum:
                - none
                - auto
                - required
            - type: object
          description: Tool choice strategy used
        tools:
          type: array
          items:
            $ref: '#/components/schemas/ResponseTool'
          description: Tools that were available
        top_logprobs:
          type: integer
          description: Number of top log probabilities
        top_p:
          type: number
          description: Top-p sampling parameter used
        truncation:
          type: string
          enum:
            - auto
            - disabled
          description: Truncation strategy used
        user:
          anyOf:
            - type: string
            - type: 'null'
          description: User identifier
        metadata:
          type: object
          additionalProperties: true
          description: Additional metadata
        usage:
          anyOf:
            - $ref: '#/components/schemas/ResponseUsage'
            - type: 'null'
          description: Usage statistics (null when response is still in progress)
      x-speakeasy-unknown-values: allow
    ResponseStreamEvent:
      description: Response stream event (data payload for SSE stream)
      type: object
      required:
        - type
      x-speakeasy-unknown-values: allow
      properties:
        type:
          type: string
          description: Event type (e.g., response.created, response.output_item.added, response.text.delta, response.completed)
        sequence_number:
          type: integer
          description: Sequence number of the event
        response:
          $ref: '#/components/schemas/ResponseObject'
          description: Response object (present in response.created, response.completed events)
        output_item:
          $ref: '#/components/schemas/ResponseOutputItem'
          description: Output item (present in response.output_item.added, response.output_item.done events)
        output_item_index:
          type: integer
          description: Index of the output item
        content_index:
          type: integer
          description: Index of the content block
        delta:
          oneOf:
            - type: string
              description: Delta text content (simple string format)
            - type: object
              description: Delta updates object format
              properties:
                text:
                  type: string
                  description: Text delta content
                role:
                  type: string
                  description: Role delta
                content:
                  type: string
                  description: Content delta
          description: Delta updates (present in response.text.delta events), can be a string or object
    CompletionRequest:
      type: object
      required:
        - model
        - prompt
      properties:
        model:
          type: string
          description: Model name
        prompt:
          type: string
          description: Prompt text
        best_of:
          type: integer
          minimum: 1
          description: Generate multiple results and return the best one
        echo:
          type: boolean
          default: false
          description: Whether to echo the prompt
        frequency_penalty:
          type: number
          minimum: -2
          maximum: 2
          default: 0
        logit_bias:
          type: object
          additionalProperties:
            type: number
        max_tokens:
          type: integer
          minimum: 1
        'n':
          type: integer
          default: 1
        presence_penalty:
          type: number
          minimum: -2
          maximum: 2
          default: 0
        seed:
          type: integer
        stop:
          oneOf:
            - type: string
            - type: array
              items:
                type: string
        stream:
          type: boolean
          default: false
        temperature:
          type: number
          minimum: 0
          maximum: 2
          default: 1
        top_p:
          type: number
          minimum: 0
          maximum: 1
          default: 1
        user:
          type: string
    CompletionChoice:
      type: object
      required:
        - text
        - index
        - finish_reason
      properties:
        text:
          type: string
        index:
          type: integer
        logprobs:
          anyOf:
            - type: object
            - type: 'null'
        finish_reason:
          type: string
          enum:
            - stop
            - length
            - content_filter
    CompletionResponse:
      type: object
      required:
        - id
        - object
        - created
        - model
        - choices
      properties:
        id:
          type: string
        object:
          type: string
          const: completion
        created:
          type: integer
        model:
          type: string
        choices:
          type: array
          items:
            $ref: '#/components/schemas/CompletionChoice'
        usage:
          $ref: '#/components/schemas/Usage'
    CompletionStreamChoice:
      type: object
      required:
        - text
        - index
      properties:
        text:
          type: string
        index:
          type: integer
        logprobs:
          anyOf:
            - type: object
            - type: 'null'
        finish_reason:
          anyOf:
            - type: string
              enum:
                - stop
                - length
                - content_filter
            - type: 'null'
    CompletionStreamEvent:
      description: Completion stream event (data payload for SSE stream)
      type: object
      required:
        - id
        - object
        - created
        - model
        - choices
      x-speakeasy-unknown-values: allow
      properties:
        id:
          type: string
        object:
          type: string
          const: completion
        created:
          type: integer
          description: Unix timestamp
        model:
          type: string
        choices:
          type: array
          items:
            $ref: '#/components/schemas/CompletionStreamChoice'
        system_fingerprint:
          type: string
        obfuscation:
          type: string
          description: Obfuscation token (server-specific field)
    EmbeddingRequest:
      type: object
      required:
        - model
        - input
      properties:
        model:
          type: string
          description: ID of the model to use. You can use the List models API to see all of your available models.
          example: text-embedding-ada-002
        input:
          oneOf:
            - type: string
              description: The string that will be turned into an embedding.
            - type: array
              items:
                type: string
              description: The array of strings that will be turned into embeddings.
            - type: array
              items:
                type: integer
              description: The array of integers (tokens) that will be turned into an embedding.
            - type: array
              items:
                type: array
                items:
                  type: integer
              description: The array of arrays containing integers (tokens) that will be turned into embeddings.
          description: Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in a single request, pass an array of strings or array of token arrays. The input must not exceed the max input tokens for the model (8192 tokens for text-embedding-ada-002), cannot be an empty string, and any array must be 2048 dimensions or less.
          example: The quick brown fox jumped over the lazy dog
        encoding_format:
          type: string
          enum:
            - float
            - base64
          default: float
          description: The format to return the embeddings in. Can be either "float" or "base64".
        dimensions:
          type: integer
          minimum: 1
          description: The number of dimensions the resulting output embeddings should have. Only supported in text-embedding-3 and later models.
        user:
          type: string
          description: A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.
    EmbeddingObject:
      type: object
      required:
        - object
        - embedding
        - index
      properties:
        object:
          type: string
          const: embedding
          description: The object type, which is always "embedding".
        embedding:
          oneOf:
            - type: array
              items:
                type: number
              description: The embedding vector, which is a list of floats.
            - type: string
              description: The embedding vector as a base64 encoded string.
          description: The embedding vector, which is a list of floats. The length of vector depends on the model.
        index:
          type: integer
          description: The index of the embedding in the list of embeddings.
    EmbeddingResponse:
      type: object
      required:
        - object
        - data
        - model
        - usage
      properties:
        object:
          type: string
          const: list
          description: The object type, which is always "list".
        data:
          type: array
          items:
            $ref: '#/components/schemas/EmbeddingObject'
          description: The list of embeddings generated by the model.
        model:
          type: string
          description: The name of the model used to generate the embedding.
        usage:
          type: object
          required:
            - prompt_tokens
            - total_tokens
          properties:
            prompt_tokens:
              type: integer
              description: The number of tokens used by the prompt.
            total_tokens:
              type: integer
              description: The total number of tokens used by the request.
          description: The usage information for the request.
    ImageGenerationRequest:
      type: object
      required:
        - prompt
      properties:
        prompt:
          type: string
          description: |
            A text description of the desired image(s).
            - Maximum length is 32000 characters for the GPT image models
            - Maximum length is 1000 characters for dall-e-2
            - Maximum length is 4000 characters for dall-e-3
        background:
          anyOf:
            - type: string
              enum:
                - transparent
                - opaque
                - auto
            - type: 'null'
          default: auto
          description: |
            Allows to set transparency for the background of the generated image(s).
            This parameter is only supported for the GPT image models.
            Must be one of transparent, opaque or auto (default value).
            When auto is used, the model will automatically determine the best background for the image.

            If transparent, the output format needs to support transparency, so it should be set to either png (default value) or webp.
        model:
          type: string
          description: |
            The model to use for image generation. One of dall-e-2, dall-e-3, or a GPT image model (gpt-image-1, gpt-image-1-mini, gpt-image-1.5).
            Defaults to dall-e-2 unless a parameter specific to the GPT image models is used.
        moderation:
          anyOf:
            - type: string
              enum:
                - low
                - auto
            - type: 'null'
          default: auto
          description: |
            Control the content-moderation level for images generated by the GPT image models.
            Must be either low for less restrictive filtering or auto (default value).
        'n':
          anyOf:
            - type: integer
            - type: 'null'
          minimum: 1
          maximum: 10
          default: 1
          description: |
            The number of images to generate. Must be between 1 and 10.
            For dall-e-3, only n=1 is supported.
        output_compression:
          anyOf:
            - type: integer
            - type: 'null'
          minimum: 0
          maximum: 100
          default: 100
          description: |
            The compression level (0-100%) for the generated images.
            This parameter is only supported for the GPT image models with the webp or jpeg output formats, and defaults to 100.
        output_format:
          anyOf:
            - type: string
              enum:
                - png
                - jpeg
                - webp
            - type: 'null'
          default: png
          description: |
            The format in which the generated images are returned.
            This parameter is only supported for the GPT image models.
            Must be one of png, jpeg, or webp.
        partial_images:
          type: integer
          minimum: 0
          maximum: 3
          default: 0
          description: |
            The number of partial images to generate.
            This parameter is used for streaming responses that return partial images.
            Value must be between 0 and 3. When set to 0, the response will be a single image sent in one streaming event.

            Note that the final image may be sent before the full number of partial images are generated if the full image is generated more quickly.
        quality:
          anyOf:
            - type: string
              enum:
                - auto
                - high
                - medium
                - low
                - hd
                - standard
            - type: 'null'
          default: auto
          description: |
            The quality of the image that will be generated.
            - auto (default value) will automatically select the best quality for the given model.
            - high, medium and low are supported for the GPT image models.
            - hd and standard are supported for dall-e-3.
            - standard is the only option for dall-e-2.
        response_format:
          anyOf:
            - type: string
              enum:
                - url
                - b64_json
            - type: 'null'
          default: url
          description: |
            The format in which generated images with dall-e-2 and dall-e-3 are returned.
            Must be one of url or b64_json. URLs are only valid for 60 minutes after the image has been generated.
            This parameter isn't supported for the GPT image models, which always return base64-encoded images.
        size:
          anyOf:
            - type: string
              enum:
                - 1024x1024
                - 1536x1024
                - 1024x1536
                - auto
                - 256x256
                - 512x512
                - 1792x1024
                - 1024x1792
            - type: 'null'
          default: auto
          description: |
            The size of the generated images.
            Must be one of 1024x1024, 1536x1024 (landscape), 1024x1536 (portrait), or auto (default value) for the GPT image models,
            one of 256x256, 512x512, or 1024x1024 for dall-e-2,
            and one of 1024x1024, 1792x1024, or 1024x1792 for dall-e-3.
        stream:
          anyOf:
            - type: boolean
            - type: 'null'
          default: false
          description: |
            Generate the image in streaming mode. Defaults to false.
            See the Image generation guide for more information.
            This parameter is only supported for the GPT image models.
        style:
          anyOf:
            - type: string
              enum:
                - vivid
                - natural
            - type: 'null'
          default: vivid
          description: |
            The style of the generated images. This parameter is only supported for dall-e-3.
            Must be one of vivid or natural.
            Vivid causes the model to lean towards generating hyper-real and dramatic images.
            Natural causes the model to produce more natural, less hyper-real looking images.
        user:
          type: string
          description: A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.
    ImageObject:
      type: object
      properties:
        url:
          type: string
          description: Image URL
        b64_json:
          type: string
          description: Base64-encoded JSON
        revised_prompt:
          type: string
          description: Revised prompt
    ImageUsage:
      type: object
      description: Usage information for image generation (provider-dependent)
      properties:
        prompt_tokens:
          type: integer
          description: Token count for the prompt
        image_tokens:
          type: integer
          description: Token count for the generated image (GPT-Image-1/1.5)
        input_text_tokens:
          type: integer
          description: Input text token count (Qwen)
        output_image_tokens:
          type: integer
          description: Output image token count (Qwen)
        width:
          type: integer
          description: Generated image width (Qwen)
        height:
          type: integer
          description: Generated image height (Qwen)
        image_count:
          type: integer
          description: Number of images generated (Qwen)
    ImageGenerationResponse:
      type: object
      required:
        - created
        - data
      properties:
        created:
          type: integer
        data:
          type: array
          items:
            $ref: '#/components/schemas/ImageObject'
        usage:
          $ref: '#/components/schemas/ImageUsage'
          description: Usage information for image generation (provider-dependent)
    ImageGenerationStreamData:
      type: object
      required:
        - index
      properties:
        index:
          type: integer
          description: Image index in the batch
        b64_json:
          type: string
          description: Base64-encoded partial or final image
        url:
          type: string
          description: Image URL (alternative to b64_json)
        progress:
          type: number
          minimum: 0
          maximum: 1
          description: Generation progress (0.0-1.0)
        is_final:
          type: boolean
          description: Whether this is the final image
        revised_prompt:
          type: string
          description: Revised prompt (if applicable)
    ImageGenerationStreamEvent:
      type: object
      required:
        - id
        - created
        - model
        - object
        - data
      properties:
        id:
          type: string
          description: Unique generation request identifier
        created:
          type: integer
          description: Unix timestamp
        model:
          type: string
          description: Model used for generation
        object:
          type: string
          enum:
            - image.generation.chunk
          description: Object type identifier
        data:
          type: array
          items:
            $ref: '#/components/schemas/ImageGenerationStreamData'
          description: Array of image data chunks
        usage:
          $ref: '#/components/schemas/ImageUsage'
          description: Usage statistics (only in final chunk)
    ImageEditRequest:
      type: object
      required:
        - image
        - prompt
      properties:
        image:
          oneOf:
            - type: string
              format: binary
              description: Single image file
            - type: array
              items:
                type: string
                format: binary
              description: Array of image files (up to 16 for GPT image models)
          description: |
            The image(s) to edit. Must be a supported image file or an array of images.

            For the GPT image models (gpt-image-1, gpt-image-1-mini, and gpt-image-1.5):
            - Each image should be a png, webp, or jpg file less than 50MB
            - You can provide up to 16 images

            For dall-e-2:
            - You can only provide one image
            - It should be a square png file less than 4MB
        prompt:
          type: string
          description: |
            A text description of the desired image(s).
            - Maximum length is 32000 characters for GPT image models
            - Maximum length is 1000 characters for dall-e-2
            - Maximum length is 4000 characters for dall-e-3
        mask:
          type: string
          format: binary
          description: |
            An additional image whose fully transparent areas (e.g. where alpha is zero) indicate where image should be edited.
            If there are multiple images provided, the mask will be applied on the first image.
            Must be a valid PNG file, less than 4MB, and have the same dimensions as image.
        background:
          anyOf:
            - type: string
              enum:
                - transparent
                - opaque
                - auto
            - type: 'null'
          default: auto
          description: |
            Allows to set transparency for the background of the generated image(s).
            This parameter is only supported for the GPT image models.
            Must be one of transparent, opaque or auto (default value).
            When auto is used, the model will automatically determine the best background for the image.

            If transparent, the output format needs to support transparency, so it should be set to either png (default value) or webp.
        input_fidelity:
          type: string
          enum:
            - high
            - low
          default: low
          description: |
            Control how much effort the model will exert to match the style and features, especially facial features, of input images.
            This parameter is only supported for gpt-image-1. Unsupported for gpt-image-1-mini.
            Supports high and low. Defaults to low.
        model:
          type: string
          description: |
            The model to use for image generation. One of dall-e-2, dall-e-3, or a GPT image model (gpt-image-1, gpt-image-1-mini, gpt-image-1.5).
            Defaults to dall-e-2 unless a parameter specific to the GPT image models is used.
        moderation:
          anyOf:
            - type: string
              enum:
                - low
                - auto
            - type: 'null'
          default: auto
          description: |
            Control the content-moderation level for images generated by the GPT image models.
            Must be either low for less restrictive filtering or auto (default value).
        'n':
          anyOf:
            - type: integer
            - type: 'null'
          minimum: 1
          maximum: 10
          default: 1
          description: |
            The number of images to generate. Must be between 1 and 10.
            For dall-e-3, only n=1 is supported.
        output_compression:
          anyOf:
            - type: integer
            - type: 'null'
          minimum: 0
          maximum: 100
          default: 100
          description: |
            The compression level (0-100%) for the generated images.
            This parameter is only supported for the GPT image models with the webp or jpeg output formats, and defaults to 100.
        output_format:
          anyOf:
            - type: string
              enum:
                - png
                - jpeg
                - webp
            - type: 'null'
          default: png
          description: |
            The format in which the generated images are returned.
            This parameter is only supported for the GPT image models.
            Must be one of png, jpeg, or webp.
        partial_images:
          type: integer
          minimum: 0
          maximum: 3
          default: 0
          description: |
            The number of partial images to generate.
            This parameter is used for streaming responses that return partial images.
            Value must be between 0 and 3. When set to 0, the response will be a single image sent in one streaming event.

            Note that the final image may be sent before the full number of partial images are generated if the full image is generated more quickly.
        quality:
          anyOf:
            - type: string
              enum:
                - auto
                - high
                - medium
                - low
                - hd
                - standard
            - type: 'null'
          default: auto
          description: |
            The quality of the image that will be generated.
            - auto (default value) will automatically select the best quality for the given model.
            - high, medium and low are supported for the GPT image models.
            - hd and standard are supported for dall-e-3.
            - standard is the only option for dall-e-2.
        response_format:
          anyOf:
            - type: string
              enum:
                - url
                - b64_json
            - type: 'null'
          default: url
          description: |
            The format in which generated images with dall-e-2 and dall-e-3 are returned.
            Must be one of url or b64_json. URLs are only valid for 60 minutes after the image has been generated.
            This parameter isn't supported for the GPT image models, which always return base64-encoded images.
        size:
          anyOf:
            - type: string
              enum:
                - 1024x1024
                - 1536x1024
                - 1024x1536
                - auto
                - 256x256
                - 512x512
                - 1792x1024
                - 1024x1792
            - type: 'null'
          default: auto
          description: |
            The size of the generated images.
            Must be one of 1024x1024, 1536x1024 (landscape), 1024x1536 (portrait), or auto (default value) for the GPT image models,
            one of 256x256, 512x512, or 1024x1024 for dall-e-2,
            and one of 1024x1024, 1792x1024, or 1024x1792 for dall-e-3.
        stream:
          anyOf:
            - type: boolean
            - type: 'null'
          default: false
          description: |
            Generate the image in streaming mode. Defaults to false.
            See the Image generation guide for more information.
            This parameter is only supported for the GPT image models.
        style:
          anyOf:
            - type: string
              enum:
                - vivid
                - natural
            - type: 'null'
          default: vivid
          description: |
            The style of the generated images. This parameter is only supported for dall-e-3.
            Must be one of vivid or natural.
            Vivid causes the model to lean towards generating hyper-real and dramatic images.
            Natural causes the model to produce more natural, less hyper-real looking images.
        user:
          type: string
          description: A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.
    ImageEditStreamData:
      type: object
      required:
        - index
      properties:
        index:
          type: integer
          description: Image index in the batch
        b64_json:
          type: string
          description: Base64-encoded partial or final image
        url:
          type: string
          description: Image URL (alternative to b64_json)
        progress:
          type: number
          minimum: 0
          maximum: 1
          description: Generation progress (0.0-1.0)
        is_final:
          type: boolean
          description: Whether this is the final image
        revised_prompt:
          type: string
          description: Revised prompt (if applicable)
    ImageEditStreamEvent:
      type: object
      required:
        - id
        - created
        - model
        - object
        - data
      properties:
        id:
          type: string
          description: Unique edit request identifier
        created:
          type: integer
          description: Unix timestamp
        model:
          type: string
          description: Model used for editing
        object:
          type: string
          enum:
            - image.edit.chunk
          description: Object type identifier
        data:
          type: array
          items:
            $ref: '#/components/schemas/ImageEditStreamData'
          description: Array of image data chunks
        usage:
          $ref: '#/components/schemas/ImageUsage'
          description: Usage statistics (only in final chunk)
    ModerationRequest:
      type: object
      required:
        - input
      properties:
        input:
          oneOf:
            - type: string
            - type: array
              items:
                type: string
          description: Input text to moderate
        model:
          type: string
          default: gpt-4o-mini
          description: Model name
    ModerationCategories:
      type: object
      properties:
        hate:
          type: boolean
        hate/threatening:
          type: boolean
        harassment:
          type: boolean
        harassment/threatening:
          type: boolean
        self-harm:
          type: boolean
        self-harm/intent:
          type: boolean
        self-harm/instructions:
          type: boolean
        sexual:
          type: boolean
        sexual/minors:
          type: boolean
        violence:
          type: boolean
        violence/graphic:
          type: boolean
    ModerationCategoryScores:
      type: object
      properties:
        hate:
          type: number
        hate/threatening:
          type: number
        harassment:
          type: number
        harassment/threatening:
          type: number
        self-harm:
          type: number
        self-harm/intent:
          type: number
        self-harm/instructions:
          type: number
        sexual:
          type: number
        sexual/minors:
          type: number
        violence:
          type: number
        violence/graphic:
          type: number
    ModerationResult:
      type: object
      required:
        - flagged
        - categories
        - category_scores
      properties:
        flagged:
          type: boolean
        categories:
          $ref: '#/components/schemas/ModerationCategories'
        category_scores:
          $ref: '#/components/schemas/ModerationCategoryScores'
    ModerationResponse:
      type: object
      required:
        - id
        - model
        - results
      properties:
        id:
          type: string
        model:
          type: string
        results:
          type: array
          items:
            $ref: '#/components/schemas/ModerationResult'
    AudioSpeechRequest:
      type: object
      required:
        - model
        - input
        - voice
      properties:
        model:
          type: string
          description: TTS model name
        input:
          type: string
          description: Text to convert to speech
        voice:
          type: string
          enum:
            - alloy
            - echo
            - fable
            - onyx
            - nova
            - shimmer
          description: Voice type
        response_format:
          type: string
          enum:
            - mp3
            - opus
            - aac
            - flac
            - wav
            - pcm
          default: mp3
        speed:
          type: number
          minimum: 0.25
          maximum: 4
          default: 1
          description: Speech speed
    AudioTranscriptionRequest:
      type: object
      required:
        - file
        - model
      properties:
        file:
          type: string
          format: binary
          description: Audio file to transcribe
        model:
          type: string
          description: Model name
        language:
          type: string
          description: Audio language (ISO-639-1 format)
        prompt:
          type: string
          description: Optional text prompt
        response_format:
          type: string
          enum:
            - json
            - text
            - srt
            - verbose_json
            - vtt
          default: json
          description: |
            Output format. Model support varies:
            - whisper-1: Supports all formats (json, text, srt, verbose_json, vtt)
            - gpt-4o-transcribe, gpt-4o-mini-transcribe: Only json and text
        temperature:
          type: number
          minimum: 0
          maximum: 1
          default: 0
        timestamp_granularities:
          type: array
          items:
            type: string
            enum:
              - word
              - segment
          description: |
            Timestamp granularity levels to include. Options: word, segment.
            **Important:** Only works when response_format is set to verbose_json.
            Note: segment timestamps have no additional latency, but word timestamps add latency.
    AudioTranscriptionResponse:
      type: object
      required:
        - text
      properties:
        text:
          type: string
          description: Transcribed text
        language:
          type: string
          description: Detected language
        duration:
          type: number
          description: Audio duration (seconds)
        words:
          type: array
          items:
            type: object
            properties:
              word:
                type: string
              start:
                type: number
              end:
                type: number
        segments:
          type: array
          items:
            type: object
            properties:
              id:
                type: integer
              seek:
                type: integer
              start:
                type: number
              end:
                type: number
              text:
                type: string
              tokens:
                type: array
                items:
                  type: integer
              temperature:
                type: number
              avg_logprob:
                type: number
              compression_ratio:
                type: number
              no_speech_prob:
                type: number
    AudioTranslationRequest:
      type: object
      required:
        - file
        - model
      properties:
        file:
          type: string
          format: binary
          description: Audio file to translate to English
        model:
          type: string
          description: Model name (whisper-1 is primary, gpt-4o-transcribe has extended support)
        prompt:
          type: string
          description: |
            Optional text prompt to guide the model's style.
            The source language can be specified in the prompt if needed, though the model will auto-detect it.
        response_format:
          type: string
          enum:
            - json
            - text
            - srt
            - verbose_json
            - vtt
          default: json
          description: Output format for the translated text
        temperature:
          type: number
          minimum: 0
          maximum: 1
          default: 0
          description: Sampling temperature between 0 and 1
    AudioTranslationResponse:
      type: object
      required:
        - text
      properties:
        text:
          type: string
          description: Translated English text
        language:
          type: string
          description: Source language
        duration:
          type: number
          description: Audio duration (seconds)
    GeminiInlineData:
      type: object
      description: Content data inline in the request (base64 encoded)
      properties:
        mime_type:
          type: string
          description: MIME type of the data (e.g., image/jpeg, image/png, audio/mp3)
          example: image/jpeg
        data:
          type: string
          description: Base64 encoded data
          example: /9j/4AAQSkZJRgABAQAAAQABAAD/2wBD...
      required:
        - mime_type
        - data
    GeminiFileData:
      type: object
      description: URI-based data reference
      properties:
        mime_type:
          type: string
          description: MIME type of the file
          example: image/jpeg
        file_uri:
          type: string
          description: URI of the file (e.g., gs:// or https://)
          example: gs://bucket/image.jpg
      required:
        - mime_type
        - file_uri
    GeminiPart:
      type: object
      description: A single part of content that can be text, inline data, file data, or function call
      oneOf:
        - type: object
          properties:
            text:
              type: string
              description: Text content
          required:
            - text
        - type: object
          properties:
            inline_data:
              $ref: '#/components/schemas/GeminiInlineData'
          required:
            - inline_data
        - type: object
          properties:
            file_data:
              $ref: '#/components/schemas/GeminiFileData'
          required:
            - file_data
        - type: object
          properties:
            functionCall:
              type: object
              description: Function call from the model
              properties:
                name:
                  type: string
                args:
                  type: object
          required:
            - functionCall
        - type: object
          properties:
            functionResponse:
              type: object
              description: Response from function execution
              properties:
                name:
                  type: string
                response:
                  type: object
          required:
            - functionResponse
    GeminiContent:
      type: object
      description: Content object containing role and parts
      properties:
        role:
          type: string
          enum:
            - user
            - model
          description: Role of the content creator
        parts:
          type: array
          description: Ordered parts that make up the content
          items:
            $ref: '#/components/schemas/GeminiPart'
          minItems: 1
      required:
        - parts
    GeminiGenerationConfig:
      type: object
      description: Configuration options for model generation
      properties:
        temperature:
          type: number
          format: float
          description: Controls randomness (0.0-2.0)
          minimum: 0
          maximum: 2
          example: 0.7
        topP:
          type: number
          format: float
          description: Nucleus sampling threshold
          minimum: 0
          maximum: 1
          example: 0.95
        topK:
          type: integer
          description: Top-k sampling parameter
          minimum: 1
          example: 40
        candidateCount:
          type: integer
          description: Number of response candidates to generate
          minimum: 1
          example: 1
        maxOutputTokens:
          type: integer
          description: Maximum number of tokens in the response
          example: 8192
        stopSequences:
          type: array
          description: Sequences that will stop generation
          items:
            type: string
          example:
            - |+


        responseMimeType:
          type: string
          description: Output format MIME type
          enum:
            - text/plain
            - application/json
            - image/png
            - image/jpeg
            - image/webp
          example: image/png
        responseSchema:
          type: object
          description: Schema for structured output (when responseMimeType is application/json)
    GeminiSafetySetting:
      type: object
      description: Safety setting for a specific harm category
      properties:
        category:
          type: string
          enum:
            - HARM_CATEGORY_HARASSMENT
            - HARM_CATEGORY_HATE_SPEECH
            - HARM_CATEGORY_SEXUALLY_EXPLICIT
            - HARM_CATEGORY_DANGEROUS_CONTENT
          description: Harm category to configure
        threshold:
          type: string
          enum:
            - BLOCK_NONE
            - BLOCK_ONLY_HIGH
            - BLOCK_MEDIUM_AND_ABOVE
            - BLOCK_LOW_AND_ABOVE
          description: Threshold for blocking content
      required:
        - category
        - threshold
    GeminiSystemInstruction:
      type: object
      description: System instruction to guide model behavior
      properties:
        parts:
          type: array
          items:
            type: object
            properties:
              text:
                type: string
          minItems: 1
      required:
        - parts
    GeminiFunctionDeclaration:
      type: object
      description: Function declaration for tool use
      properties:
        name:
          type: string
          description: Function name
        description:
          type: string
          description: Function description
        parameters:
          type: object
          description: OpenAPI 3.0 schema object for parameters
      required:
        - name
        - description
    GeminiTool:
      type: object
      description: Tool that the model can use
      properties:
        functionDeclarations:
          type: array
          items:
            $ref: '#/components/schemas/GeminiFunctionDeclaration'
    GeminiToolConfig:
      type: object
      description: Tool configuration
      properties:
        functionCallingConfig:
          type: object
          properties:
            mode:
              type: string
              enum:
                - AUTO
                - ANY
                - NONE
              description: Function calling mode
    GeminiGenerateContentRequest:
      type: object
      description: Request to generate content
      properties:
        contents:
          type: array
          description: Content array (conversation history)
          items:
            $ref: '#/components/schemas/GeminiContent'
          minItems: 1
        generationConfig:
          $ref: '#/components/schemas/GeminiGenerationConfig'
        safetySettings:
          type: array
          items:
            $ref: '#/components/schemas/GeminiSafetySetting'
        systemInstruction:
          $ref: '#/components/schemas/GeminiSystemInstruction'
        tools:
          type: array
          items:
            $ref: '#/components/schemas/GeminiTool'
        toolConfig:
          $ref: '#/components/schemas/GeminiToolConfig'
        cachedContent:
          type: string
          description: Cached content reference
      required:
        - contents
    GeminiSafetyRating:
      type: object
      description: Safety rating for a piece of content
      properties:
        category:
          type: string
          description: Harm category
        probability:
          type: string
          enum:
            - NEGLIGIBLE
            - LOW
            - MEDIUM
            - HIGH
          description: Probability of harm
        blocked:
          type: boolean
          description: Whether content was blocked
    GeminiCandidate:
      type: object
      description: A response candidate
      properties:
        content:
          $ref: '#/components/schemas/GeminiContent'
        finishReason:
          type: string
          enum:
            - STOP
            - MAX_TOKENS
            - SAFETY
            - RECITATION
            - OTHER
          description: Reason for finishing generation
        safetyRatings:
          type: array
          items:
            $ref: '#/components/schemas/GeminiSafetyRating'
        citationMetadata:
          type: object
          description: Citation information
        tokenCount:
          type: integer
          description: Token count for this candidate
    GeminiPromptFeedback:
      type: object
      description: Feedback about the prompt
      properties:
        blockReason:
          type: string
          enum:
            - BLOCK_REASON_UNSPECIFIED
            - SAFETY
            - OTHER
          description: Reason for blocking the prompt
        safetyRatings:
          type: array
          items:
            $ref: '#/components/schemas/GeminiSafetyRating'
    GeminiUsageMetadata:
      type: object
      description: Token usage metadata
      properties:
        promptTokenCount:
          type: integer
          description: Number of tokens in the prompt
        candidatesTokenCount:
          type: integer
          description: Total tokens across all candidates
        totalTokenCount:
          type: integer
          description: Total token count
        cachedContentTokenCount:
          type: integer
          description: Cached content token count
    GeminiGenerateContentResponse:
      type: object
      description: Response from generateContent or streamGenerateContent
      properties:
        candidates:
          type: array
          items:
            $ref: '#/components/schemas/GeminiCandidate'
        promptFeedback:
          $ref: '#/components/schemas/GeminiPromptFeedback'
        usageMetadata:
          $ref: '#/components/schemas/GeminiUsageMetadata'
        modelVersion:
          type: string
          description: Model version used
          example: gemini-2.0-flash-001
        responseId:
          type: string
          description: Unique identifier for this response
        modelStatus:
          type: object
          description: Current model operational status
    GeminiEmbedContentRequest:
      type: object
      description: Request to generate embeddings
      properties:
        content:
          $ref: '#/components/schemas/GeminiContent'
        taskType:
          type: string
          enum:
            - RETRIEVAL_QUERY
            - RETRIEVAL_DOCUMENT
            - SEMANTIC_SIMILARITY
            - CLASSIFICATION
            - CLUSTERING
            - QUESTION_ANSWERING
            - FACT_VERIFICATION
            - CODE_RETRIEVAL_QUERY
          description: Task type for the embedding
        title:
          type: string
          description: Optional title (for RETRIEVAL_DOCUMENT task type)
        outputDimensionality:
          type: integer
          description: Reduced dimension for output embedding
          minimum: 1
          example: 256
      required:
        - content
    GeminiEmbedding:
      type: object
      description: Embedding vector
      properties:
        values:
          type: array
          description: Embedding values (floats)
          items:
            type: number
            format: float
      required:
        - values
    GeminiEmbedContentResponse:
      type: object
      description: Response from embedContent
      properties:
        embedding:
          $ref: '#/components/schemas/GeminiEmbedding'
      required:
        - embedding
    GeminiBatchRequestItem:
      type: object
      description: Single request in a batch with optional metadata
      properties:
        request:
          $ref: '#/components/schemas/GeminiGenerateContentRequest'
        metadata:
          type: object
          description: Optional metadata for tracking this request
          additionalProperties:
            type: string
      required:
        - request
    GeminiInlineRequestConfig:
      type: object
      description: Inline requests configuration (max 20MB)
      properties:
        requests:
          type: array
          description: Array of request items
          items:
            $ref: '#/components/schemas/GeminiBatchRequestItem'
          minItems: 1
      required:
        - requests
    GeminiInputConfig:
      type: object
      description: Input configuration - either inline requests or file reference
      oneOf:
        - type: object
          properties:
            requests:
              $ref: '#/components/schemas/GeminiInlineRequestConfig'
          required:
            - requests
        - type: object
          properties:
            file_name:
              type: string
              description: JSONL file reference
              example: files/abc123
          required:
            - file_name
    GeminiJobState:
      type: string
      description: State of the batch job
      enum:
        - JOB_STATE_UNSPECIFIED
        - JOB_STATE_PENDING
        - JOB_STATE_RUNNING
        - JOB_STATE_SUCCEEDED
        - JOB_STATE_FAILED
        - JOB_STATE_CANCELLED
        - JOB_STATE_EXPIRED
    GeminiInlineResponseItem:
      type: object
      description: Single response item in batch results
      properties:
        response:
          $ref: '#/components/schemas/GeminiGenerateContentResponse'
        error:
          type: object
          description: Error if this request failed
          properties:
            code:
              type: integer
            message:
              type: string
            status:
              type: string
    GeminiOutputConfig:
      type: object
      description: Output configuration containing results
      properties:
        inlined_responses:
          type: array
          description: Inline response results (for inline input)
          items:
            $ref: '#/components/schemas/GeminiInlineResponseItem'
        file_name:
          type: string
          description: Output JSONL file name (for file input)
          example: files/output_xyz789
    GeminiBatchError:
      type: object
      description: Error information for failed batch job
      properties:
        code:
          type: integer
          description: Error code
        message:
          type: string
          description: Error message
        status:
          type: string
          description: Error status
    GeminiBatchStats:
      type: object
      description: Statistics about batch processing
      properties:
        failedRequestCount:
          type: integer
          description: Number of failed requests
        successfulRequestCount:
          type: integer
          description: Number of successful requests
  responses:
    AuthenticationError:
      description: Invalid API Key or authentication failed
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/AuthenticationError'
    PermissionDeniedError:
      description: Insufficient permissions
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/PermissionDeniedError'
    InternalServerError:
      description: Internal server error
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/InternalServerError'
    NotFoundError:
      description: Requested resource not found
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/NotFoundError'
    BadRequestError:
      description: Invalid request parameters or unable to parse
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/BadRequestError'
    ConflictError:
      description: Resource conflict (reserved for future use)
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/ConflictError'
    UnprocessableEntityError:
      description: Parameter format is correct but semantically invalid
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/UnprocessableEntityError'
    RateLimitError:
      description: Rate limit exceeded or insufficient balance
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/RateLimitError'
    ServiceUnavailableError:
      description: Service temporarily unavailable or under maintenance
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/ServiceUnavailableError'
