"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from r9s.types import BaseModel
from typing import Literal, Optional
from typing_extensions import NotRequired, TypedDict


Quality = Literal[
    "standard",
    "hd",
    # Extended quality options for GPT-Image models
    "low",
    "medium",
    "high",
]


ImageGenerationRequestResponseFormat = Literal[
    "url",
    "b64_json",
]


Size = Literal[
    # DALL-E 2 sizes
    "256x256",
    "512x512",
    "1024x1024",
    # DALL-E 3 sizes
    "1792x1024",
    "1024x1792",
    # GPT-Image-1 / GPT-Image-1.5 sizes
    "1024x1536",
    "1536x1024",
    # Wanx / Ali sizes
    "720x1280",
    "1280x720",
    "512x1024",
    "1024x768",
    "576x1024",
    "1024x576",
    # Gemini Nano Banana aspect ratios
    "1:1",
    "16:9",
    "9:16",
    "4:3",
    "3:4",
    "3:2",
    "2:3",
    "5:4",
    "4:5",
    "21:9",
]


Style = Literal[
    "vivid",
    "natural",
]


ImageGenerationBackground = Literal[
    "transparent",
    "opaque",
    "auto",
]


ImageGenerationModeration = Literal[
    "low",
    "auto",
]


ImageGenerationOutputFormat = Literal[
    "png",
    "jpeg",
    "webp",
]


class ImageGenerationRequestTypedDict(TypedDict):
    prompt: str
    r"""Image description prompt"""
    model: NotRequired[str]
    r"""Model name"""
    n: NotRequired[int]
    r"""Number of images to generate"""
    quality: NotRequired[Quality]
    response_format: NotRequired[ImageGenerationRequestResponseFormat]
    size: NotRequired[Size]
    style: NotRequired[Style]
    user: NotRequired[str]
    # GPT Image model parameters
    background: NotRequired[ImageGenerationBackground]
    r"""Background transparency setting (transparent/opaque/auto). GPT models only."""
    moderation: NotRequired[ImageGenerationModeration]
    r"""Content moderation level (low/auto). GPT models only."""
    output_compression: NotRequired[int]
    r"""Compression level (0-100%) for webp/jpeg. GPT models only."""
    output_format: NotRequired[ImageGenerationOutputFormat]
    r"""Output format (png/jpeg/webp). GPT models only."""
    partial_images: NotRequired[int]
    r"""Number of partial images for streaming (0-3). GPT models only."""
    stream: NotRequired[bool]
    r"""Enable streaming mode. GPT models only."""
    # Extended parameters for advanced providers
    negative_prompt: NotRequired[str]
    r"""Negative prompt to exclude elements (Qwen, Stability). Max 500 chars for Qwen."""
    seed: NotRequired[int]
    r"""Random seed for reproducibility. Range: 0-2147483647 for Qwen."""
    prompt_extend: NotRequired[bool]
    r"""Enable AI prompt optimization (Qwen-specific)."""
    watermark: NotRequired[bool]
    r"""Add watermark to generated images (Qwen-specific)."""


class ImageGenerationRequest(BaseModel):
    prompt: str
    r"""Image description prompt"""

    model: Optional[str] = None
    r"""Model name"""

    n: Optional[int] = 1
    r"""Number of images to generate. Range depends on model:
    - dall-e-2: 1-10
    - dall-e-3: 1
    - gpt-image-1: 1
    - gpt-image-1.5: 1-10
    - wanx-v1: 1
    - gemini-*: 1
    """

    quality: Optional[Quality] = "standard"
    r"""Image quality. Options depend on model:
    - dall-e-3: 'standard', 'hd'
    - gpt-image-1/1.5: 'low', 'medium', 'high', 'standard', 'hd'
    - gemini-*: 'standard' (1K), 'hd' (2K)
    """

    response_format: Optional[ImageGenerationRequestResponseFormat] = "url"

    size: Optional[Size] = "1024x1024"
    r"""Image size. Options depend on model. Can also use aspect ratios for Gemini/Minimax."""

    style: Optional[Style] = "vivid"

    user: Optional[str] = None

    # GPT Image model parameters
    background: Optional[ImageGenerationBackground] = None
    r"""Background transparency setting (transparent/opaque/auto). Only for GPT image models. Defaults to auto."""

    moderation: Optional[ImageGenerationModeration] = None
    r"""Content moderation level (low/auto). Only for GPT image models. Defaults to auto."""

    output_compression: Optional[int] = None
    r"""Compression level (0-100%) for webp/jpeg output formats. Only for GPT image models. Defaults to 100."""

    output_format: Optional[ImageGenerationOutputFormat] = None
    r"""Output format (png/jpeg/webp). Only for GPT image models. Defaults to png."""

    partial_images: Optional[int] = None
    r"""Number of partial images for streaming (0-3). Only for GPT image models with stream=True. Defaults to 0."""

    stream: Optional[bool] = None
    r"""Enable streaming mode. Only for GPT image models. Defaults to false."""

    # Extended parameters for advanced providers
    negative_prompt: Optional[str] = None
    r"""Negative prompt to exclude elements (Qwen, Stability). Max 500 chars for Qwen."""

    seed: Optional[int] = None
    r"""Random seed for reproducibility. Range: 0-2147483647 for Qwen."""

    prompt_extend: Optional[bool] = None
    r"""Enable AI prompt optimization (Qwen-specific)."""

    watermark: Optional[bool] = None
    r"""Add watermark to generated images (Qwen-specific)."""
