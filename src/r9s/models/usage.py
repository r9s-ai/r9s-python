"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from r9s.types import BaseModel
from typing import Optional
from typing_extensions import NotRequired, TypedDict


class PromptTokensDetailsTypedDict(TypedDict):
    r"""Details about prompt tokens"""

    cached_tokens: NotRequired[int]
    r"""Number of cached tokens"""
    audio_tokens: NotRequired[int]
    r"""Number of audio tokens in the prompt"""


class PromptTokensDetails(BaseModel):
    r"""Details about prompt tokens"""

    cached_tokens: Optional[int] = None
    r"""Number of cached tokens"""

    audio_tokens: Optional[int] = None
    r"""Number of audio tokens in the prompt"""


class CompletionTokensDetailsTypedDict(TypedDict):
    r"""Details about completion tokens"""

    reasoning_tokens: NotRequired[int]
    r"""Number of reasoning tokens"""
    audio_tokens: NotRequired[int]
    r"""Number of audio tokens"""
    accepted_prediction_tokens: NotRequired[int]
    r"""Number of accepted prediction tokens"""
    rejected_prediction_tokens: NotRequired[int]
    r"""Number of rejected prediction tokens"""


class CompletionTokensDetails(BaseModel):
    r"""Details about completion tokens"""

    reasoning_tokens: Optional[int] = None
    r"""Number of reasoning tokens"""

    audio_tokens: Optional[int] = None
    r"""Number of audio tokens"""

    accepted_prediction_tokens: Optional[int] = None
    r"""Number of accepted prediction tokens"""

    rejected_prediction_tokens: Optional[int] = None
    r"""Number of rejected prediction tokens"""


class UsageTypedDict(TypedDict):
    prompt_tokens: int
    r"""Number of tokens in the prompt (input)"""
    completion_tokens: int
    r"""Number of tokens in the completion (output)"""
    total_tokens: int
    r"""Total number of tokens (prompt + completion)"""
    prompt_tokens_details: NotRequired[PromptTokensDetailsTypedDict]
    r"""Details about prompt tokens"""
    completion_tokens_details: NotRequired[CompletionTokensDetailsTypedDict]
    r"""Details about completion tokens"""


class Usage(BaseModel):
    prompt_tokens: int
    r"""Number of tokens in the prompt (input)"""

    completion_tokens: int
    r"""Number of tokens in the completion (output)"""

    total_tokens: int
    r"""Total number of tokens (prompt + completion)"""

    prompt_tokens_details: Optional[PromptTokensDetails] = None
    r"""Details about prompt tokens"""

    completion_tokens_details: Optional[CompletionTokensDetails] = None
    r"""Details about completion tokens"""
