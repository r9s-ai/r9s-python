"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from .anthropiccontent import AnthropicContent, AnthropicContentTypedDict
import pydantic
from pydantic import model_serializer
from pydantic.functional_validators import AfterValidator
from r9s.types import BaseModel, Nullable, OptionalNullable, UNSET, UNSET_SENTINEL
from r9s.utils import validate_const
from typing import List, Literal, Optional
from typing_extensions import Annotated, NotRequired, TypedDict


StopReason = Literal[
    "end_turn",
    "max_tokens",
    "stop_sequence",
    "tool_use",
    "pause_turn",
    "refusal",
]
r"""Reason why the model stopped:
- end_turn: Natural completion
- max_tokens: Hit max_tokens limit
- stop_sequence: Hit a stop sequence
- tool_use: Model wants to use a tool
- pause_turn: Long-running task paused (extended thinking)
- refusal: Content policy violation

"""


class AnthropicMessageResponseUsageTypedDict(TypedDict):
    input_tokens: int
    r"""Number of input tokens used"""
    output_tokens: int
    r"""Number of output tokens generated"""
    cache_creation_input_tokens: NotRequired[int]
    r"""Number of input tokens used to create cache entries (only present if prompt caching is used)"""
    cache_read_input_tokens: NotRequired[int]
    r"""Number of input tokens read from cache (only present if prompt caching is used)"""


class AnthropicMessageResponseUsage(BaseModel):
    input_tokens: int
    r"""Number of input tokens used"""

    output_tokens: int
    r"""Number of output tokens generated"""

    cache_creation_input_tokens: Optional[int] = None
    r"""Number of input tokens used to create cache entries (only present if prompt caching is used)"""

    cache_read_input_tokens: Optional[int] = None
    r"""Number of input tokens read from cache (only present if prompt caching is used)"""


class AnthropicMessageResponseTypedDict(TypedDict):
    id: str
    content: List[AnthropicContentTypedDict]
    model: str
    stop_reason: Nullable[StopReason]
    r"""Reason why the model stopped:
    - end_turn: Natural completion
    - max_tokens: Hit max_tokens limit
    - stop_sequence: Hit a stop sequence
    - tool_use: Model wants to use a tool
    - pause_turn: Long-running task paused (extended thinking)
    - refusal: Content policy violation

    """
    usage: AnthropicMessageResponseUsageTypedDict
    type: Literal["message"]
    role: Literal["assistant"]
    stop_sequence: NotRequired[Nullable[str]]


class AnthropicMessageResponse(BaseModel):
    id: str

    content: List[AnthropicContent]

    model: str

    stop_reason: Nullable[StopReason]
    r"""Reason why the model stopped:
    - end_turn: Natural completion
    - max_tokens: Hit max_tokens limit
    - stop_sequence: Hit a stop sequence
    - tool_use: Model wants to use a tool
    - pause_turn: Long-running task paused (extended thinking)
    - refusal: Content policy violation

    """

    usage: AnthropicMessageResponseUsage

    TYPE: Annotated[
        Annotated[Literal["message"], AfterValidator(validate_const("message"))],
        pydantic.Field(alias="type"),
    ] = "message"

    ROLE: Annotated[
        Annotated[Literal["assistant"], AfterValidator(validate_const("assistant"))],
        pydantic.Field(alias="role"),
    ] = "assistant"

    stop_sequence: OptionalNullable[str] = UNSET

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = ["stop_sequence"]
        nullable_fields = ["stop_reason", "stop_sequence"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m
