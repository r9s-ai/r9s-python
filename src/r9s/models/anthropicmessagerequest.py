"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from .anthropicmessagemessage import (
    AnthropicMessageMessage,
    AnthropicMessageMessageTypedDict,
)
from .anthropictool import AnthropicTool, AnthropicToolTypedDict
import pydantic
from pydantic.functional_validators import AfterValidator
from r9s.types import BaseModel
from r9s.utils import validate_const
from typing import Any, Dict, List, Literal, Optional, Union
from typing_extensions import Annotated, NotRequired, TypeAliasType, TypedDict


class AnthropicMessageRequest2TypedDict(TypedDict):
    type: Literal["tool"]
    name: NotRequired[str]


class AnthropicMessageRequest2(BaseModel):
    TYPE: Annotated[
        Annotated[Optional[Literal["tool"]], AfterValidator(validate_const("tool"))],
        pydantic.Field(alias="type"),
    ] = "tool"

    name: Optional[str] = None


AnthropicMessageRequest1 = Literal[
    "none",
    "auto",
    "any",
]


AnthropicMessageRequestToolChoiceTypedDict = TypeAliasType(
    "AnthropicMessageRequestToolChoiceTypedDict",
    Union[AnthropicMessageRequest2TypedDict, AnthropicMessageRequest1],
)


AnthropicMessageRequestToolChoice = TypeAliasType(
    "AnthropicMessageRequestToolChoice",
    Union[AnthropicMessageRequest2, AnthropicMessageRequest1],
)


AnthropicMessageRequestType = Literal[
    "enabled",
    "disabled",
]
r"""Whether to enable extended thinking"""


class ThinkingTypedDict(TypedDict):
    r"""Configuration for extended thinking (Claude 3.7+). When enabled, the model will spend more time thinking before responding."""

    type: NotRequired[AnthropicMessageRequestType]
    r"""Whether to enable extended thinking"""
    budget_tokens: NotRequired[int]
    r"""Maximum number of tokens to use for thinking (1000-10000)"""


class Thinking(BaseModel):
    r"""Configuration for extended thinking (Claude 3.7+). When enabled, the model will spend more time thinking before responding."""

    type: Optional[AnthropicMessageRequestType] = "disabled"
    r"""Whether to enable extended thinking"""

    budget_tokens: Optional[int] = None
    r"""Maximum number of tokens to use for thinking (1000-10000)"""


AnthropicMessageRequestServiceTier = Literal[
    "auto",
    "standard_only",
]
r"""Service tier for request processing:
- auto: Automatically select between standard and priority capacity
- standard_only: Only use standard capacity (may have longer wait times during high load)

"""


class AnthropicMessageRequestTypedDict(TypedDict):
    model: str
    r"""Claude model name"""
    messages: List[AnthropicMessageMessageTypedDict]
    r"""Messages list, first message must be a user message"""
    system: NotRequired[str]
    r"""System prompt"""
    max_tokens: NotRequired[int]
    r"""Maximum number of output tokens (optional).
    If not provided, the relay service or API may use a default value.
    Different models have different maximum values.

    """
    stop_sequences: NotRequired[List[str]]
    r"""Stop sequences"""
    stream: NotRequired[bool]
    temperature: NotRequired[float]
    top_p: NotRequired[float]
    top_k: NotRequired[int]
    r"""Top-k sampling parameter. Only sample from the top K options for each subsequent token."""
    tools: NotRequired[List[AnthropicToolTypedDict]]
    tool_choice: NotRequired[AnthropicMessageRequestToolChoiceTypedDict]
    metadata: NotRequired[Dict[str, Any]]
    r"""An object describing metadata about the request. Can be used for tracking, identification, or filtering purposes.
    Common use cases: user_id, session_id, request_id, etc.

    """
    thinking: NotRequired[ThinkingTypedDict]
    r"""Configuration for extended thinking (Claude 3.7+). When enabled, the model will spend more time thinking before responding.

    """
    service_tier: NotRequired[AnthropicMessageRequestServiceTier]
    r"""Service tier for request processing:
    - auto: Automatically select between standard and priority capacity
    - standard_only: Only use standard capacity (may have longer wait times during high load)

    """


class AnthropicMessageRequest(BaseModel):
    model: str
    r"""Claude model name"""

    messages: List[AnthropicMessageMessage]
    r"""Messages list, first message must be a user message"""

    system: Optional[str] = None
    r"""System prompt"""

    max_tokens: Optional[int] = None
    r"""Maximum number of output tokens (optional).
    If not provided, the relay service or API may use a default value.
    Different models have different maximum values.

    """

    stop_sequences: Optional[List[str]] = None
    r"""Stop sequences"""

    stream: Optional[bool] = False

    temperature: Optional[float] = None

    top_p: Optional[float] = None

    top_k: Optional[int] = None
    r"""Top-k sampling parameter. Only sample from the top K options for each subsequent token."""

    tools: Optional[List[AnthropicTool]] = None

    tool_choice: Optional[AnthropicMessageRequestToolChoice] = None

    metadata: Optional[Dict[str, Any]] = None
    r"""An object describing metadata about the request. Can be used for tracking, identification, or filtering purposes.
    Common use cases: user_id, session_id, request_id, etc.

    """

    thinking: Optional[Thinking] = None
    r"""Configuration for extended thinking (Claude 3.7+). When enabled, the model will spend more time thinking before responding.

    """

    service_tier: Optional[AnthropicMessageRequestServiceTier] = "auto"
    r"""Service tier for request processing:
    - auto: Automatically select between standard and priority capacity
    - standard_only: Only use standard capacity (may have longer wait times during high load)

    """
