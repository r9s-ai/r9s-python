openapi: 3.1.0
components:
  schemas:
    Message:
      type: object
      required:
      - role
      description: 'Message object. Note: Different API endpoints have different field
        requirements and support.


        **Field support:**

        - /v1/chat/completions: Supports all fields (tool_calls, tool_call_id, etc.)

        - /v1/responses: Only supports basic fields (role, content, name); does not
        support tool_calls and tool_call_id


        **content field requirements:**

        - /v1/chat/completions: When tool_calls is present, content can be omitted
        or null

        - /v1/responses: content field is always required and cannot be null; tool_calls
        field is not supported

        '
      properties:
        role:
          type: string
          enum:
          - system
          - user
          - assistant
          - tool
          description: Message role
        content:
          anyOf:
          - type: string
          - type: array
            items:
              $ref: '#/components/schemas/MessageContent'
          - type: 'null'
          description: 'Message content. Can be null when assistant message contains
            tool_calls.

            - user/system messages: Required, contains text or multimodal content

            - assistant messages: Optional when tool_calls is present; can be null
            or omitted

            - tool messages: Required, contains tool return results (usually JSON
            string)


            **Important:** In /v1/responses API, content field must exist and cannot
            be null.

            For /v1/chat/completions, content can be null when tool_calls is present.

            '
        name:
          type: string
          description: Sender name
        reasoning_content:
          type: string
          description: Reasoning content
        tool_calls:
          type: array
          items:
            $ref: '#/components/schemas/ToolCall'
          description: Tool calls list
        tool_call_id:
          type: string
          description: Tool call ID
    MessageContent:
      type: object
      required:
      - type
      properties:
        type:
          type: string
          enum:
          - text
          - image_url
        text:
          type: string
        image_url:
          $ref: '#/components/schemas/ImageURL'
    ImageURL:
      type: object
      required:
      - url
      properties:
        url:
          type: string
        detail:
          type: string
          enum:
          - auto
          - low
          - high
    ToolCall:
      type: object
      required:
      - id
      - type
      - function
      properties:
        id:
          type: string
        type:
          type: string
        function:
          $ref: '#/components/schemas/FunctionCall'
    FunctionCall:
      type: object
      required:
      - name
      properties:
        name:
          type: string
        arguments:
          type: string
    Tool:
      type: object
      required:
      - type
      - function
      description: 'Tool definition (nested format). Used for /v1/chat/completions
        and other endpoints.

        Format: { "type": "function", "function": { "name": "...", "description":
        "...", "parameters": {...} } }

        '
      properties:
        type:
          type: string
          enum:
          - function
          description: Tool type, currently only supports function
        function:
          type: object
          required:
          - name
          properties:
            name:
              type: string
              description: Function name
            description:
              type: string
              description: Function description, helps model understand when to call
                this function
            parameters:
              type: object
              description: Function parameter definition in JSON Schema format
              additionalProperties: true
    ResponseTool:
      type: object
      required:
      - type
      - name
      description: 'Tool definition (flat format). Dedicated for /v1/responses endpoint.

        Format: { "type": "function", "name": "...", "description": "...", "parameters":
        {...} }

        '
      properties:
        type:
          type: string
          enum:
          - function
          description: Tool type, currently only supports function
        name:
          type: string
          description: Function name
        description:
          type: string
          description: Function description, helps model understand when to call this
            function
        parameters:
          type: object
          description: Function parameter definition in JSON Schema format
          additionalProperties: true
          properties:
            type:
              type: string
              enum:
              - object
            properties:
              type: object
              additionalProperties: true
            required:
              type: array
              items:
                type: string
    ResponseFormat:
      type: object
      properties:
        type:
          type: string
          enum:
          - text
          - json_object
          - json_schema
        json_schema:
          $ref: '#/components/schemas/JsonSchema'
    JsonSchema:
      type: object
      properties:
        name:
          type: string
        description:
          type: string
        schema:
          type: object
          additionalProperties: true
    Audio:
      type: object
      properties:
        voice:
          type: string
          enum:
          - alloy
          - echo
          - fable
          - onyx
          - nova
          - shimmer
          description: Voice type for audio output
        format:
          type: string
          enum:
          - mp3
          - opus
          - aac
          - flac
          - wav
          - pcm
          description: Audio output format
    StreamOptions:
      type: object
      properties:
        include_usage:
          type: boolean
          description: Whether to include usage statistics
    Usage:
      type: object
      required:
      - prompt_tokens
      - completion_tokens
      - total_tokens
      properties:
        prompt_tokens:
          type: integer
          description: Number of tokens in the prompt (input)
        prompt_tokens_details:
          type: object
          description: Details about prompt tokens
          properties:
            cached_tokens:
              type: integer
              description: Number of cached tokens
            audio_tokens:
              type: integer
              description: Number of audio tokens in the prompt
        completion_tokens:
          type: integer
          description: Number of tokens in the completion (output)
        completion_tokens_details:
          type: object
          description: Details about completion tokens
          properties:
            reasoning_tokens:
              type: integer
              description: Number of reasoning tokens
            audio_tokens:
              type: integer
              description: Number of audio tokens
            accepted_prediction_tokens:
              type: integer
              description: Number of accepted prediction tokens
            rejected_prediction_tokens:
              type: integer
              description: Number of rejected prediction tokens
        total_tokens:
          type: integer
          description: Total number of tokens (prompt + completion)
    ResponseUsage:
      type: object
      required:
      - input_tokens
      - output_tokens
      - total_tokens
      properties:
        input_tokens:
          type: integer
          description: Number of tokens in the input
        input_tokens_details:
          type: object
          description: Details about input tokens
          properties:
            cached_tokens:
              type: integer
              description: Number of cached tokens
        output_tokens:
          type: integer
          description: Number of tokens in the output
        output_tokens_details:
          type: object
          description: Details about output tokens
          properties:
            reasoning_tokens:
              type: integer
              description: Number of reasoning tokens
        total_tokens:
          type: integer
          description: Total number of tokens (input + output)
    ChatCompletionRequest:
      type: object
      required:
      - model
      - messages
      properties:
        model:
          type: string
          description: Model name
        messages:
          type: array
          items:
            $ref: '#/components/schemas/Message'
          description: Messages list
        frequency_penalty:
          type: number
          minimum: -2.0
          maximum: 2.0
        logit_bias:
          type: object
          additionalProperties:
            type: number
        logprobs:
          type: boolean
          description: When true, stream must be false (OpenAI constraint)
        top_logprobs:
          type: integer
          minimum: 0
          maximum: 20
        max_tokens:
          type: integer
          minimum: 1
        n:
          type: integer
          minimum: 1
          maximum: 128
          description: Number of chat completion choices to generate
        modalities:
          type: array
          items:
            type: string
            enum:
            - text
            - audio
          description: Output modality types. Use ["text", "audio"] for audio output
        audio:
          $ref: '#/components/schemas/Audio'
          description: Audio output configuration (when modalities includes audio)
        presence_penalty:
          type: number
          minimum: -2.0
          maximum: 2.0
        response_format:
          $ref: '#/components/schemas/ResponseFormat'
        seed:
          type: integer
        service_tier:
          type: string
          enum:
          - auto
          - default
        stop:
          oneOf:
          - type: string
          - type: array
            items:
              type: string
        stream:
          type: boolean
          default: false
        stream_options:
          $ref: '#/components/schemas/StreamOptions'
        temperature:
          type: number
          minimum: 0.0
          maximum: 2.0
        top_p:
          type: number
          minimum: 0.0
          maximum: 1.0
        top_k:
          type: integer
          minimum: 1
          description: Top-k sampling parameter (non-OpenAI standard, model-specific)
        tools:
          type: array
          items:
            $ref: '#/components/schemas/Tool'
        tool_choice:
          oneOf:
          - type: string
            enum:
            - none
            - auto
            - required
          - type: object
            properties:
              type:
                type: string
                const: function
              function:
                type: object
                properties:
                  name:
                    type: string
        parallel_tool_calls:
          type: boolean
          description: Whether to enable parallel function calling during tool use.
            Only valid when tools are specified.
        user:
          type: string
          description: Unique identifier representing end-user for abuse monitoring
        reasoning_effort:
          type: string
          enum:
          - low
          - medium
          - high
          description: Reasoning effort level for o1 series models (low, medium, high)
        max_completion_tokens:
          type: integer
          minimum: 1
          description: Maximum number of tokens to generate in the completion (alternative
            to max_tokens, more precise)
        store:
          type: boolean
          description: Whether to store the output for use in model distillation or
            evals
        metadata:
          type: object
          additionalProperties: true
          description: Custom metadata to attach to the request for tracking purposes
    ChatCompletionChoice:
      type: object
      required:
      - index
      - message
      - finish_reason
      properties:
        index:
          type: integer
        message:
          $ref: '#/components/schemas/Message'
        finish_reason:
          type: string
          enum:
          - stop
          - length
          - tool_calls
          - content_filter
        logprobs:
          type: object
    ChatCompletionResponse:
      type: object
      required:
      - id
      - object
      - created
      - model
      - choices
      properties:
        id:
          type: string
        object:
          type: string
          const: chat.completion
        created:
          type: integer
        model:
          type: string
        choices:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionChoice'
        usage:
          $ref: '#/components/schemas/Usage'
        system_fingerprint:
          type: string
    ChatCompletionStreamDelta:
      type: object
      properties:
        role:
          type: string
          enum:
          - system
          - user
          - assistant
        content:
          type: string
        tool_calls:
          type: array
          items:
            $ref: '#/components/schemas/ToolCall'
        reasoning_content:
          type: string
    ChatCompletionStreamChoice:
      type: object
      required:
      - index
      - delta
      properties:
        index:
          type: integer
        delta:
          $ref: '#/components/schemas/ChatCompletionStreamDelta'
        finish_reason:
          anyOf:
          - type: string
            enum:
            - stop
            - length
            - tool_calls
            - content_filter
          - type: 'null'
        logprobs:
          type: object
    ChatCompletionStreamEvent:
      description: Chat completion chunk event (data payload for SSE stream)
      type: object
      required:
      - id
      - object
      - created
      - model
      - choices
      x-speakeasy-unknown-values: allow
      properties:
        id:
          type: string
        object:
          type: string
          const: chat.completion.chunk
        created:
          type: integer
          description: Unix timestamp
        model:
          type: string
        choices:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionStreamChoice'
          description: Array of completion choices. May be empty in the final chunk
            when only usage is returned.
        system_fingerprint:
          type: string
        usage:
          $ref: '#/components/schemas/Usage'
          description: Usage information (only present in the last chunk when stream_options.include_usage
            is true)
    ResponseRequest:
      type: object
      required:
      - model
      - input
      properties:
        model:
          type: string
          description: Model name
        input:
          oneOf:
          - type: string
          - type: array
            items:
              $ref: '#/components/schemas/Message'
          description: 'Input content, required parameter. Can be:

            - String: Single text input

            - Message array: Structured conversation history


            **Important limitations:**

            - Messages only support basic fields (role, content, name)

            - Does not support tool_calls, tool_call_id and other tool-related fields

            - content field is required and cannot be null

            - To use tools, define them in the top-level tools parameter; model will
            call them on first response


            Note: Responses API has deprecated messages parameter, now uses input
            parameter uniformly

            '
        instructions:
          type: string
          description: System-level instructions to guide model behavior and response
            style (similar to system message)
        temperature:
          type: number
          minimum: 0.0
          maximum: 2.0
          description: Controls output randomness, higher values mean more random
        top_p:
          type: number
          minimum: 0.0
          maximum: 1.0
          description: Nucleus sampling parameter, controls output diversity
        max_output_tokens:
          type: integer
          minimum: 1
          description: Maximum number of tokens to generate
        stream:
          type: boolean
          default: false
          description: Whether to enable streaming
        modalities:
          type: array
          items:
            type: string
            enum:
            - text
            - audio
          description: Response modality types
        tools:
          type: array
          items:
            $ref: '#/components/schemas/ResponseTool'
          description: Available tools list (using flat format)
        tool_choice:
          oneOf:
          - type: string
            enum:
            - none
            - auto
            - required
          - $ref: '#/components/schemas/ToolChoice'
          description: Tool selection strategy
        parallel_tool_calls:
          type: boolean
          default: true
          description: Whether to enable parallel function calling during tool use.
            When false, ensures exactly zero or one tool is called.
        text:
          type: object
          description: Text output configuration
          properties:
            format:
              type: object
              description: 'An object specifying the format that the model must output.
                Setting to { "type": "json_schema", "name": "...", "schema": {...}
                } enables Structured Outputs which ensures the model will match your
                supplied JSON schema.

                Setting to { "type": "json_object" } enables JSON mode, which ensures
                the model generates valid JSON.

                '
              properties:
                type:
                  type: string
                  enum:
                  - text
                  - json_object
                  - json_schema
                  description: The type of response format
                name:
                  type: string
                  description: Name for the schema (required when type is json_schema)
                schema:
                  type: object
                  description: JSON schema definition for structured outputs
                  additionalProperties: true
                strict:
                  type: boolean
                  description: Whether to enforce strict schema matching
            verbosity:
              type: string
              enum:
              - low
              - medium
              - high
              description: Verbosity level for the text output
        previous_response_id:
          type: string
          description: 'The ID of a previous response to continue the conversation
            from. This allows you to chain responses together and maintain conversation
            state.

            When using previous_response_id, the model will automatically have access
            to all previously produced reasoning items and conversation history.

            '
        store:
          type: boolean
          default: true
          description: 'Whether to store the generated model response for later retrieval
            via API.

            Defaults to true. Set to false to disable storage (required for ZDR organizations).

            '
        background:
          type: boolean
          default: false
          description: Whether to run the model response in the background asynchronously.
            Useful for long-running tasks.
        reasoning:
          type: object
          description: Configuration for reasoning models (e.g., o1, o3, gpt-5). Controls
            how the model uses reasoning tokens to "think" through the problem.
          properties:
            effort:
              type: string
              enum:
              - none
              - minimal
              - low
              - medium
              - high
              - xhigh
              description: The effort level for reasoning (none/minimal=fast, low/medium=balanced,
                high/xhigh=thorough)
            summary:
              type: string
              description: Summary of reasoning approach
        truncation:
          type: string
          enum:
          - auto
          - disabled
          default: disabled
          description: 'The truncation strategy to use for the model response.

            - auto: If input exceeds context window, truncate by dropping items from
            beginning

            - disabled: Request fails with 400 error if input exceeds context window
            (default)

            '
        stop:
          oneOf:
          - type: string
          - type: array
            items:
              type: string
          description: Up to 4 sequences where the API will stop generating further
            tokens
        metadata:
          type: object
          additionalProperties: true
          description: Additional metadata for tracking and organization purposes
    ToolChoice:
      type: object
      required:
      - type
      - function
      description: Specify specific tool selection
      properties:
        type:
          type: string
          const: function
          description: Tool type
        function:
          type: object
          required:
          - name
          properties:
            name:
              type: string
              description: Function name to call
    ResponseObject:
      type: object
      required:
      - id
      - object
      - created_at
      - status
      - model
      properties:
        id:
          type: string
          description: Unique identifier for the response
        object:
          type: string
          const: response
        created_at:
          type: integer
          description: Unix timestamp when the response was created
        status:
          type: string
          enum:
          - in_progress
          - completed
          - incomplete
          - failed
          - cancelled
          description: The status of the response
        background:
          type: boolean
          description: Whether the response is running in the background
        billing:
          type: object
          description: Billing information
          properties:
            payer:
              type: string
              enum:
              - developer
              - organization
              description: Who is paying for this response
        completed_at:
          anyOf:
          - type: integer
          - type: 'null'
          description: Unix timestamp when the response was completed
        error:
          anyOf:
          - type: object
          - type: 'null'
          description: Error information if the response failed
        incomplete_details:
          anyOf:
          - type: object
          - type: 'null'
          description: Details about why the response is incomplete
        instructions:
          type: string
          description: System-level instructions that guided the model's behavior
        max_output_tokens:
          type: integer
          description: Maximum number of tokens to generate
        max_tool_calls:
          anyOf:
          - type: integer
          - type: 'null'
          description: Maximum number of tool calls allowed
        model:
          type: string
          description: The model used for the response
        output:
          type: array
          items:
            $ref: '#/components/schemas/ResponseOutputItem'
          description: Array of output items produced by the model
        parallel_tool_calls:
          type: boolean
          description: Whether parallel tool calls are enabled
        previous_response_id:
          anyOf:
          - type: string
          - type: 'null'
          description: ID of the previous response in a chain
        prompt_cache_key:
          anyOf:
          - type: string
          - type: 'null'
          description: Key for prompt caching
        prompt_cache_retention:
          anyOf:
          - type: string
          - type: 'null'
          description: Prompt cache retention policy
        reasoning:
          type: object
          description: Reasoning configuration
          properties:
            effort:
              anyOf:
              - type: string
                enum:
                - none
                - minimal
                - low
                - medium
                - high
                - xhigh
              - type: 'null'
              description: Reasoning effort level (none/minimal for fast, low/medium
                for balanced, high/xhigh for thorough)
            summary:
              anyOf:
              - type: string
              - type: 'null'
              description: Summary of reasoning
        safety_identifier:
          anyOf:
          - type: string
          - type: 'null'
          description: Safety identifier for the response
        service_tier:
          type: string
          enum:
          - auto
          - default
          description: Service tier used
        store:
          type: boolean
          description: Whether to store the response
        temperature:
          type: number
          description: Temperature parameter used
        text:
          type: object
          description: Text format configuration
          properties:
            format:
              type: object
              properties:
                type:
                  type: string
                  enum:
                  - text
                  - json_object
                  - json_schema
            verbosity:
              type: string
              enum:
              - low
              - medium
              - high
              description: Verbosity level
        tool_choice:
          oneOf:
          - type: string
            enum:
            - none
            - auto
            - required
          - type: object
          description: Tool choice strategy used
        tools:
          type: array
          items:
            $ref: '#/components/schemas/ResponseTool'
          description: Tools that were available
        top_logprobs:
          type: integer
          description: Number of top log probabilities
        top_p:
          type: number
          description: Top-p sampling parameter used
        truncation:
          type: string
          enum:
          - auto
          - disabled
          description: Truncation strategy used
        user:
          anyOf:
          - type: string
          - type: 'null'
          description: User identifier
        metadata:
          type: object
          additionalProperties: true
          description: Additional metadata
        usage:
          anyOf:
          - $ref: '#/components/schemas/ResponseUsage'
          - type: 'null'
          description: Usage statistics (null when response is still in progress)
      x-speakeasy-unknown-values: allow
    ResponseOutputItem:
      type: object
      required:
      - id
      - type
      properties:
        id:
          type: string
          description: Unique identifier for output item
        type:
          type: string
          enum:
          - message
          - function_call
          - reasoning
          description: Output type (message for final response, function_call for
            tool calls, reasoning for reasoning trace)
        status:
          type: string
          enum:
          - completed
          - in_progress
          - incomplete
          description: Output status
        role:
          type: string
          enum:
          - user
          - assistant
          description: Message role
        content:
          type: array
          description: Content array
          items:
            type: object
            properties:
              type:
                type: string
                enum:
                - text
                - refusal
                - output_text
                - reasoning_text
                description: Content type (text for messages, output_text for responses,
                  reasoning_text for reasoning traces, refusal for safety refusals)
              text:
                type: string
                description: Text content
              refusal:
                type: string
                description: Refusal content
              annotations:
                type: array
                description: Content annotations
              logprobs:
                type: array
                description: Log probabilities
        call_id:
          type: string
          description: Function call ID
        name:
          type: string
          description: Function name
        arguments:
          type: string
          description: Function arguments (JSON string)
        output:
          type: string
          description: Function output
        summary:
          anyOf:
          - type: string
          - type: array
          - type: 'null'
          description: Natural-language summary of reasoning (for reasoning type),
            can be string or array
        encrypted_content:
          anyOf:
          - type: string
          - type: 'null'
          description: Encrypted reasoning tokens for stateless workflows (for reasoning
            type)
    ResponseStreamEvent:
      description: Response stream event (data payload for SSE stream)
      type: object
      required:
      - type
      x-speakeasy-unknown-values: allow
      properties:
        type:
          type: string
          description: Event type (e.g., response.created, response.output_item.added,
            response.text.delta, response.completed)
        sequence_number:
          type: integer
          description: Sequence number of the event
        response:
          $ref: '#/components/schemas/ResponseObject'
          description: Response object (present in response.created, response.completed
            events)
        output_item:
          $ref: '#/components/schemas/ResponseOutputItem'
          description: Output item (present in response.output_item.added, response.output_item.done
            events)
        output_item_index:
          type: integer
          description: Index of the output item
        content_index:
          type: integer
          description: Index of the content block
        delta:
          oneOf:
          - type: string
            description: Delta text content (simple string format)
          - type: object
            description: Delta updates object format
            properties:
              text:
                type: string
                description: Text delta content
              role:
                type: string
                description: Role delta
              content:
                type: string
                description: Content delta
          description: Delta updates (present in response.text.delta events), can
            be a string or object
    CompletionRequest:
      type: object
      required:
      - model
      - prompt
      properties:
        model:
          type: string
          description: Model name
        prompt:
          type: string
          description: Prompt text
        best_of:
          type: integer
          minimum: 1
          description: Generate multiple results and return the best one
        echo:
          type: boolean
          default: false
          description: Whether to echo the prompt
        frequency_penalty:
          type: number
          minimum: -2.0
          maximum: 2.0
          default: 0
        logit_bias:
          type: object
          additionalProperties:
            type: number
        max_tokens:
          type: integer
          minimum: 1
        n:
          type: integer
          default: 1
        presence_penalty:
          type: number
          minimum: -2.0
          maximum: 2.0
          default: 0
        seed:
          type: integer
        stop:
          oneOf:
          - type: string
          - type: array
            items:
              type: string
        stream:
          type: boolean
          default: false
        temperature:
          type: number
          minimum: 0.0
          maximum: 2.0
          default: 1.0
        top_p:
          type: number
          minimum: 0.0
          maximum: 1.0
          default: 1.0
        user:
          type: string
    CompletionChoice:
      type: object
      required:
      - text
      - index
      - finish_reason
      properties:
        text:
          type: string
        index:
          type: integer
        logprobs:
          anyOf:
          - type: object
          - type: 'null'
        finish_reason:
          type: string
          enum:
          - stop
          - length
          - content_filter
    CompletionResponse:
      type: object
      required:
      - id
      - object
      - created
      - model
      - choices
      properties:
        id:
          type: string
        object:
          type: string
          const: completion
        created:
          type: integer
        model:
          type: string
        choices:
          type: array
          items:
            $ref: '#/components/schemas/CompletionChoice'
        usage:
          $ref: '#/components/schemas/Usage'
    CompletionStreamChoice:
      type: object
      required:
      - text
      - index
      properties:
        text:
          type: string
        index:
          type: integer
        logprobs:
          anyOf:
          - type: object
          - type: 'null'
        finish_reason:
          anyOf:
          - type: string
            enum:
            - stop
            - length
            - content_filter
          - type: 'null'
    CompletionStreamEvent:
      description: Completion stream event (data payload for SSE stream)
      type: object
      required:
      - id
      - object
      - created
      - model
      - choices
      x-speakeasy-unknown-values: allow
      properties:
        id:
          type: string
        object:
          type: string
          const: completion
        created:
          type: integer
          description: Unix timestamp
        model:
          type: string
        choices:
          type: array
          items:
            $ref: '#/components/schemas/CompletionStreamChoice'
        system_fingerprint:
          type: string
        obfuscation:
          type: string
          description: Obfuscation token (server-specific field)
    ImageGenerationRequest:
      type: object
      required:
      - prompt
      properties:
        prompt:
          type: string
          description: 'A text description of the desired image(s).

            - Maximum length is 32000 characters for the GPT image models

            - Maximum length is 1000 characters for dall-e-2

            - Maximum length is 4000 characters for dall-e-3

            '
        background:
          anyOf:
          - type: string
            enum:
            - transparent
            - opaque
            - auto
          - type: 'null'
          default: auto
          description: 'Allows to set transparency for the background of the generated
            image(s).

            This parameter is only supported for the GPT image models.

            Must be one of transparent, opaque or auto (default value).

            When auto is used, the model will automatically determine the best background
            for the image.


            If transparent, the output format needs to support transparency, so it
            should be set to either png (default value) or webp.

            '
        model:
          type: string
          description: 'The model to use for image generation. One of dall-e-2, dall-e-3,
            or a GPT image model (gpt-image-1, gpt-image-1-mini, gpt-image-1.5).

            Defaults to dall-e-2 unless a parameter specific to the GPT image models
            is used.

            '
        moderation:
          anyOf:
          - type: string
            enum:
            - low
            - auto
          - type: 'null'
          default: auto
          description: 'Control the content-moderation level for images generated
            by the GPT image models.

            Must be either low for less restrictive filtering or auto (default value).

            '
        n:
          anyOf:
          - type: integer
          - type: 'null'
          minimum: 1
          maximum: 10
          default: 1
          description: 'The number of images to generate. Must be between 1 and 10.

            For dall-e-3, only n=1 is supported.

            '
        output_compression:
          anyOf:
          - type: integer
          - type: 'null'
          minimum: 0
          maximum: 100
          default: 100
          description: 'The compression level (0-100%) for the generated images.

            This parameter is only supported for the GPT image models with the webp
            or jpeg output formats, and defaults to 100.

            '
        output_format:
          anyOf:
          - type: string
            enum:
            - png
            - jpeg
            - webp
          - type: 'null'
          default: png
          description: 'The format in which the generated images are returned.

            This parameter is only supported for the GPT image models.

            Must be one of png, jpeg, or webp.

            '
        partial_images:
          type: integer
          minimum: 0
          maximum: 3
          default: 0
          description: 'The number of partial images to generate.

            This parameter is used for streaming responses that return partial images.

            Value must be between 0 and 3. When set to 0, the response will be a single
            image sent in one streaming event.


            Note that the final image may be sent before the full number of partial
            images are generated if the full image is generated more quickly.

            '
        quality:
          anyOf:
          - type: string
            enum:
            - auto
            - high
            - medium
            - low
            - hd
            - standard
          - type: 'null'
          default: auto
          description: 'The quality of the image that will be generated.

            - auto (default value) will automatically select the best quality for
            the given model.

            - high, medium and low are supported for the GPT image models.

            - hd and standard are supported for dall-e-3.

            - standard is the only option for dall-e-2.

            '
        response_format:
          anyOf:
          - type: string
            enum:
            - url
            - b64_json
          - type: 'null'
          default: url
          description: 'The format in which generated images with dall-e-2 and dall-e-3
            are returned.

            Must be one of url or b64_json. URLs are only valid for 60 minutes after
            the image has been generated.

            This parameter isn''t supported for the GPT image models, which always
            return base64-encoded images.

            '
        size:
          anyOf:
          - type: string
            enum:
            - 1024x1024
            - 1536x1024
            - 1024x1536
            - auto
            - 256x256
            - 512x512
            - 1792x1024
            - 1024x1792
          - type: 'null'
          default: auto
          description: 'The size of the generated images.

            Must be one of 1024x1024, 1536x1024 (landscape), 1024x1536 (portrait),
            or auto (default value) for the GPT image models,

            one of 256x256, 512x512, or 1024x1024 for dall-e-2,

            and one of 1024x1024, 1792x1024, or 1024x1792 for dall-e-3.

            '
        stream:
          anyOf:
          - type: boolean
          - type: 'null'
          default: false
          description: 'Generate the image in streaming mode. Defaults to false.

            See the Image generation guide for more information.

            This parameter is only supported for the GPT image models.

            '
        style:
          anyOf:
          - type: string
            enum:
            - vivid
            - natural
          - type: 'null'
          default: vivid
          description: 'The style of the generated images. This parameter is only
            supported for dall-e-3.

            Must be one of vivid or natural.

            Vivid causes the model to lean towards generating hyper-real and dramatic
            images.

            Natural causes the model to produce more natural, less hyper-real looking
            images.

            '
        user:
          type: string
          description: A unique identifier representing your end-user, which can help
            OpenAI to monitor and detect abuse.
    ImageEditRequest:
      type: object
      required:
      - image
      - prompt
      properties:
        image:
          oneOf:
          - type: string
            format: binary
            description: Single image file
          - type: array
            items:
              type: string
              format: binary
            description: Array of image files (up to 16 for GPT image models)
          description: 'The image(s) to edit. Must be a supported image file or an
            array of images.


            For the GPT image models (gpt-image-1, gpt-image-1-mini, and gpt-image-1.5):

            - Each image should be a png, webp, or jpg file less than 50MB

            - You can provide up to 16 images


            For dall-e-2:

            - You can only provide one image

            - It should be a square png file less than 4MB

            '
        prompt:
          type: string
          description: 'A text description of the desired image(s).

            - Maximum length is 32000 characters for GPT image models

            - Maximum length is 1000 characters for dall-e-2

            - Maximum length is 4000 characters for dall-e-3

            '
        mask:
          type: string
          format: binary
          description: 'An additional image whose fully transparent areas (e.g. where
            alpha is zero) indicate where image should be edited.

            If there are multiple images provided, the mask will be applied on the
            first image.

            Must be a valid PNG file, less than 4MB, and have the same dimensions
            as image.

            '
        background:
          anyOf:
          - type: string
            enum:
            - transparent
            - opaque
            - auto
          - type: 'null'
          default: auto
          description: 'Allows to set transparency for the background of the generated
            image(s).

            This parameter is only supported for the GPT image models.

            Must be one of transparent, opaque or auto (default value).

            When auto is used, the model will automatically determine the best background
            for the image.


            If transparent, the output format needs to support transparency, so it
            should be set to either png (default value) or webp.

            '
        input_fidelity:
          type: string
          enum:
          - high
          - low
          default: low
          description: 'Control how much effort the model will exert to match the
            style and features, especially facial features, of input images.

            This parameter is only supported for gpt-image-1. Unsupported for gpt-image-1-mini.

            Supports high and low. Defaults to low.

            '
        model:
          type: string
          description: 'The model to use for image generation. One of dall-e-2, dall-e-3,
            or a GPT image model (gpt-image-1, gpt-image-1-mini, gpt-image-1.5).

            Defaults to dall-e-2 unless a parameter specific to the GPT image models
            is used.

            '
        moderation:
          anyOf:
          - type: string
            enum:
            - low
            - auto
          - type: 'null'
          default: auto
          description: 'Control the content-moderation level for images generated
            by the GPT image models.

            Must be either low for less restrictive filtering or auto (default value).

            '
        n:
          anyOf:
          - type: integer
          - type: 'null'
          minimum: 1
          maximum: 10
          default: 1
          description: 'The number of images to generate. Must be between 1 and 10.

            For dall-e-3, only n=1 is supported.

            '
        output_compression:
          anyOf:
          - type: integer
          - type: 'null'
          minimum: 0
          maximum: 100
          default: 100
          description: 'The compression level (0-100%) for the generated images.

            This parameter is only supported for the GPT image models with the webp
            or jpeg output formats, and defaults to 100.

            '
        output_format:
          anyOf:
          - type: string
            enum:
            - png
            - jpeg
            - webp
          - type: 'null'
          default: png
          description: 'The format in which the generated images are returned.

            This parameter is only supported for the GPT image models.

            Must be one of png, jpeg, or webp.

            '
        partial_images:
          type: integer
          minimum: 0
          maximum: 3
          default: 0
          description: 'The number of partial images to generate.

            This parameter is used for streaming responses that return partial images.

            Value must be between 0 and 3. When set to 0, the response will be a single
            image sent in one streaming event.


            Note that the final image may be sent before the full number of partial
            images are generated if the full image is generated more quickly.

            '
        quality:
          anyOf:
          - type: string
            enum:
            - auto
            - high
            - medium
            - low
            - hd
            - standard
          - type: 'null'
          default: auto
          description: 'The quality of the image that will be generated.

            - auto (default value) will automatically select the best quality for
            the given model.

            - high, medium and low are supported for the GPT image models.

            - hd and standard are supported for dall-e-3.

            - standard is the only option for dall-e-2.

            '
        response_format:
          anyOf:
          - type: string
            enum:
            - url
            - b64_json
          - type: 'null'
          default: url
          description: 'The format in which generated images with dall-e-2 and dall-e-3
            are returned.

            Must be one of url or b64_json. URLs are only valid for 60 minutes after
            the image has been generated.

            This parameter isn''t supported for the GPT image models, which always
            return base64-encoded images.

            '
        size:
          anyOf:
          - type: string
            enum:
            - 1024x1024
            - 1536x1024
            - 1024x1536
            - auto
            - 256x256
            - 512x512
            - 1792x1024
            - 1024x1792
          - type: 'null'
          default: auto
          description: 'The size of the generated images.

            Must be one of 1024x1024, 1536x1024 (landscape), 1024x1536 (portrait),
            or auto (default value) for the GPT image models,

            one of 256x256, 512x512, or 1024x1024 for dall-e-2,

            and one of 1024x1024, 1792x1024, or 1024x1792 for dall-e-3.

            '
        stream:
          anyOf:
          - type: boolean
          - type: 'null'
          default: false
          description: 'Generate the image in streaming mode. Defaults to false.

            See the Image generation guide for more information.

            This parameter is only supported for the GPT image models.

            '
        style:
          anyOf:
          - type: string
            enum:
            - vivid
            - natural
          - type: 'null'
          default: vivid
          description: 'The style of the generated images. This parameter is only
            supported for dall-e-3.

            Must be one of vivid or natural.

            Vivid causes the model to lean towards generating hyper-real and dramatic
            images.

            Natural causes the model to produce more natural, less hyper-real looking
            images.

            '
        user:
          type: string
          description: A unique identifier representing your end-user, which can help
            OpenAI to monitor and detect abuse.
    ImageObject:
      type: object
      properties:
        url:
          type: string
          description: Image URL
        b64_json:
          type: string
          description: Base64-encoded JSON
        revised_prompt:
          type: string
          description: Revised prompt
    ImageGenerationResponse:
      type: object
      required:
      - created
      - data
      properties:
        created:
          type: integer
        data:
          type: array
          items:
            $ref: '#/components/schemas/ImageObject'
        usage:
          $ref: '#/components/schemas/ImageUsage'
          description: Usage information for image generation (provider-dependent)
    ImageUsage:
      type: object
      description: Usage information for image generation (provider-dependent)
      properties:
        prompt_tokens:
          type: integer
          description: Token count for the prompt
        image_tokens:
          type: integer
          description: Token count for the generated image (GPT-Image-1/1.5)
        input_text_tokens:
          type: integer
          description: Input text token count (Qwen)
        output_image_tokens:
          type: integer
          description: Output image token count (Qwen)
        width:
          type: integer
          description: Generated image width (Qwen)
        height:
          type: integer
          description: Generated image height (Qwen)
        image_count:
          type: integer
          description: Number of images generated (Qwen)
    ImageEditStreamData:
      type: object
      required:
      - index
      properties:
        index:
          type: integer
          description: Image index in the batch
        b64_json:
          type: string
          description: Base64-encoded partial or final image
        url:
          type: string
          description: Image URL (alternative to b64_json)
        progress:
          type: number
          minimum: 0.0
          maximum: 1.0
          description: Generation progress (0.0-1.0)
        is_final:
          type: boolean
          description: Whether this is the final image
        revised_prompt:
          type: string
          description: Revised prompt (if applicable)
    ImageEditStreamEvent:
      type: object
      required:
      - id
      - created
      - model
      - object
      - data
      properties:
        id:
          type: string
          description: Unique edit request identifier
        created:
          type: integer
          description: Unix timestamp
        model:
          type: string
          description: Model used for editing
        object:
          type: string
          enum:
          - image.edit.chunk
          description: Object type identifier
        data:
          type: array
          items:
            $ref: '#/components/schemas/ImageEditStreamData'
          description: Array of image data chunks
        usage:
          $ref: '#/components/schemas/ImageUsage'
          description: Usage statistics (only in final chunk)
    ImageGenerationStreamData:
      type: object
      required:
      - index
      properties:
        index:
          type: integer
          description: Image index in the batch
        b64_json:
          type: string
          description: Base64-encoded partial or final image
        url:
          type: string
          description: Image URL (alternative to b64_json)
        progress:
          type: number
          minimum: 0.0
          maximum: 1.0
          description: Generation progress (0.0-1.0)
        is_final:
          type: boolean
          description: Whether this is the final image
        revised_prompt:
          type: string
          description: Revised prompt (if applicable)
    ImageGenerationStreamEvent:
      type: object
      required:
      - id
      - created
      - model
      - object
      - data
      properties:
        id:
          type: string
          description: Unique generation request identifier
        created:
          type: integer
          description: Unix timestamp
        model:
          type: string
          description: Model used for generation
        object:
          type: string
          enum:
          - image.generation.chunk
          description: Object type identifier
        data:
          type: array
          items:
            $ref: '#/components/schemas/ImageGenerationStreamData'
          description: Array of image data chunks
        usage:
          $ref: '#/components/schemas/ImageUsage'
          description: Usage statistics (only in final chunk)
    EmbeddingRequest:
      type: object
      required:
      - model
      - input
      properties:
        model:
          type: string
          description: ID of the model to use. You can use the List models API to
            see all of your available models.
          example: text-embedding-ada-002
        input:
          oneOf:
          - type: string
            description: The string that will be turned into an embedding.
          - type: array
            items:
              type: string
            description: The array of strings that will be turned into embeddings.
          - type: array
            items:
              type: integer
            description: The array of integers (tokens) that will be turned into an
              embedding.
          - type: array
            items:
              type: array
              items:
                type: integer
            description: The array of arrays containing integers (tokens) that will
              be turned into embeddings.
          description: Input text to embed, encoded as a string or array of tokens.
            To embed multiple inputs in a single request, pass an array of strings
            or array of token arrays. The input must not exceed the max input tokens
            for the model (8192 tokens for text-embedding-ada-002), cannot be an empty
            string, and any array must be 2048 dimensions or less.
          example: The quick brown fox jumped over the lazy dog
        encoding_format:
          type: string
          enum:
          - float
          - base64
          default: float
          description: The format to return the embeddings in. Can be either "float"
            or "base64".
        dimensions:
          type: integer
          minimum: 1
          description: The number of dimensions the resulting output embeddings should
            have. Only supported in text-embedding-3 and later models.
        user:
          type: string
          description: A unique identifier representing your end-user, which can help
            OpenAI to monitor and detect abuse.
    EmbeddingObject:
      type: object
      required:
      - object
      - embedding
      - index
      properties:
        object:
          type: string
          const: embedding
          description: The object type, which is always "embedding".
        embedding:
          oneOf:
          - type: array
            items:
              type: number
            description: The embedding vector, which is a list of floats.
          - type: string
            description: The embedding vector as a base64 encoded string.
          description: The embedding vector, which is a list of floats. The length
            of vector depends on the model.
        index:
          type: integer
          description: The index of the embedding in the list of embeddings.
    EmbeddingResponse:
      type: object
      required:
      - object
      - data
      - model
      - usage
      properties:
        object:
          type: string
          const: list
          description: The object type, which is always "list".
        data:
          type: array
          items:
            $ref: '#/components/schemas/EmbeddingObject'
          description: The list of embeddings generated by the model.
        model:
          type: string
          description: The name of the model used to generate the embedding.
        usage:
          type: object
          required:
          - prompt_tokens
          - total_tokens
          properties:
            prompt_tokens:
              type: integer
              description: The number of tokens used by the prompt.
            total_tokens:
              type: integer
              description: The total number of tokens used by the request.
          description: The usage information for the request.
    ModerationRequest:
      type: object
      required:
      - input
      properties:
        input:
          oneOf:
          - type: string
          - type: array
            items:
              type: string
          description: Input text to moderate
        model:
          type: string
          default: gpt-4o-mini
          description: Model name
    ModerationCategories:
      type: object
      properties:
        hate:
          type: boolean
        hate/threatening:
          type: boolean
        harassment:
          type: boolean
        harassment/threatening:
          type: boolean
        self-harm:
          type: boolean
        self-harm/intent:
          type: boolean
        self-harm/instructions:
          type: boolean
        sexual:
          type: boolean
        sexual/minors:
          type: boolean
        violence:
          type: boolean
        violence/graphic:
          type: boolean
    ModerationCategoryScores:
      type: object
      properties:
        hate:
          type: number
        hate/threatening:
          type: number
        harassment:
          type: number
        harassment/threatening:
          type: number
        self-harm:
          type: number
        self-harm/intent:
          type: number
        self-harm/instructions:
          type: number
        sexual:
          type: number
        sexual/minors:
          type: number
        violence:
          type: number
        violence/graphic:
          type: number
    ModerationResult:
      type: object
      required:
      - flagged
      - categories
      - category_scores
      properties:
        flagged:
          type: boolean
        categories:
          $ref: '#/components/schemas/ModerationCategories'
        category_scores:
          $ref: '#/components/schemas/ModerationCategoryScores'
    ModerationResponse:
      type: object
      required:
      - id
      - model
      - results
      properties:
        id:
          type: string
        model:
          type: string
        results:
          type: array
          items:
            $ref: '#/components/schemas/ModerationResult'
    AudioSpeechRequest:
      type: object
      required:
      - model
      - input
      - voice
      properties:
        model:
          type: string
          description: TTS model name
        input:
          type: string
          description: Text to convert to speech
        voice:
          type: string
          enum:
          - alloy
          - echo
          - fable
          - onyx
          - nova
          - shimmer
          description: Voice type
        response_format:
          type: string
          enum:
          - mp3
          - opus
          - aac
          - flac
          - wav
          - pcm
          default: mp3
        speed:
          type: number
          minimum: 0.25
          maximum: 4.0
          default: 1.0
          description: Speech speed
    AudioTranscriptionRequest:
      type: object
      required:
      - file
      - model
      properties:
        file:
          type: string
          format: binary
          description: Audio file to transcribe
        model:
          type: string
          description: Model name
        language:
          type: string
          description: Audio language (ISO-639-1 format)
        prompt:
          type: string
          description: Optional text prompt
        response_format:
          type: string
          enum:
          - json
          - text
          - srt
          - verbose_json
          - vtt
          default: json
          description: 'Output format. Model support varies:

            - whisper-1: Supports all formats (json, text, srt, verbose_json, vtt)

            - gpt-4o-transcribe, gpt-4o-mini-transcribe: Only json and text

            '
        temperature:
          type: number
          minimum: 0.0
          maximum: 1.0
          default: 0
        timestamp_granularities:
          type: array
          items:
            type: string
            enum:
            - word
            - segment
          description: 'Timestamp granularity levels to include. Options: word, segment.

            **Important:** Only works when response_format is set to verbose_json.

            Note: segment timestamps have no additional latency, but word timestamps
            add latency.

            '
    AudioTranscriptionResponse:
      type: object
      required:
      - text
      properties:
        text:
          type: string
          description: Transcribed text
        language:
          type: string
          description: Detected language
        duration:
          type: number
          description: Audio duration (seconds)
        words:
          type: array
          items:
            type: object
            properties:
              word:
                type: string
              start:
                type: number
              end:
                type: number
        segments:
          type: array
          items:
            type: object
            properties:
              id:
                type: integer
              seek:
                type: integer
              start:
                type: number
              end:
                type: number
              text:
                type: string
              tokens:
                type: array
                items:
                  type: integer
              temperature:
                type: number
              avg_logprob:
                type: number
              compression_ratio:
                type: number
              no_speech_prob:
                type: number
    AudioTranslationRequest:
      type: object
      required:
      - file
      - model
      properties:
        file:
          type: string
          format: binary
          description: Audio file to translate to English
        model:
          type: string
          description: Model name (whisper-1 is primary, gpt-4o-transcribe has extended
            support)
        prompt:
          type: string
          description: 'Optional text prompt to guide the model''s style.

            The source language can be specified in the prompt if needed, though the
            model will auto-detect it.

            '
        response_format:
          type: string
          enum:
          - json
          - text
          - srt
          - verbose_json
          - vtt
          default: json
          description: Output format for the translated text
        temperature:
          type: number
          minimum: 0.0
          maximum: 1.0
          default: 0
          description: Sampling temperature between 0 and 1
    AudioTranslationResponse:
      type: object
      required:
      - text
      properties:
        text:
          type: string
          description: Translated English text
        language:
          type: string
          description: Source language
        duration:
          type: number
          description: Audio duration (seconds)
